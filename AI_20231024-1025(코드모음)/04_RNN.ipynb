{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5bb3ee-105f-430b-82c2-362e745d713e",
   "metadata": {},
   "source": [
    "### RNN (Recurrent Neural Network)\n",
    "- \n",
    "RNN은 시퀀스 데(텍스트, 시계열 데이터, 음성 신호 등 순서가 중요한 데이터)이터를 처리하기 위해 설계된 신경망의 한 유형입니\n",
    "- . R은 는 이전 시간 단계의 정보를 현재 시간 단계의 입력과 결합하여 패턴을 인식하는 것입니\n",
    "- <img src='rnn_model.png'><img src='rnn_model1.png'>다.\n",
    "\n",
    "#### RNN의 특징:\n",
    "1. **메모리**: RNN은 이전의 정보를 기억할 수 있으며, 이 정보는 현재 입력의 처리에 사용됩니다.\n",
    "2. **시간 단계**: RNN은 Time Step를 통해 데이터를 처리합니다. 각 시간 단계에서 RNN은 이전 TimeStep의 상태와 현재 TimeStep의 입력을 사용하여 출력물을 생성합니다\n",
    "\n",
    "### Keras에서 RNN -수 있게 해줍니다. RNN을 구성할 때 `SimpleRNN`, `LSTM`, `GRU`와 같은 RNN 레이어를 사용구성하는 예시입니다:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential()\n",
    "# RNN 레이어 추가\n",
    "# 입력 형태는 (timesteps, features)입니다.\n",
    "# 여기서는 8개의 시간 단계와 4개의 특성을 가진 데이터를 사용한다고 가정합니다.\n",
    "model.add(SimpleRNN(50, input_shape=(8, 4), return_sequences=True))\n",
    "model.add(SimpleRNN(50))\n",
    "# 출력 레이어`timr= :loss='mse')\n",
    "```\n",
    "\n",
    "이 예시에서, 우리는 두 개의 `SimpleRN나의 `Dense` 레이어로 구성된 모델을 만들었습니다. `S음\n",
    "(D_{h} × D_{h})eRNN` 레이어는 각각 50개의 유닛을 가지고 있습니다.\n",
    "\n",
    "### 입력 형태\n",
    "RNN 레이어의 `input_shape` 매개변수는 입력 데이터의 형태를 정의합니다. 이는 `(timesteps, features)` 형태의 튜플로 지정됩니다.\n",
    "\n",
    "- `timesteps`: 시퀀스의 길이, 즉 시간 단계의 수입니다.\n",
    "- `features`: 각 시간 단계에서의 특성의 수입니다.\n",
    "\n",
    "`return_sequences` 매개변수는 RNN 레이어가 모든 시간 단계의 출력을 반환할지, 아니면 마지막 시간 단계의 출력만 반환할지를 결정합니다. 첫 번째 `SimpleRNN` 레이어에서는 `return_sequences=모델을 구축할 수 있으며, 입력 형태와 모델 구조를 쉽게 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca3d49",
   "metadata": {},
   "source": [
    "# Simple RNN을 구성함에 있어서 timestep 과 input_dim 이 중요한 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893b73c",
   "metadata": {},
   "source": [
    "## SimpleRNN 모델에서 timestep과 input_dim은 모델 아키텍처와 데이터 형태를 정의하는 중요한 매개변수이다. ##\n",
    "\n",
    "1. timestep (타임스텝):\n",
    "\n",
    "- 1) timestep은 시퀀스 데이터를 처리하는 데 필요한 시간 단계(time step)의 수를 나타냄\n",
    "- 2) 시계열 데이터나 순차적 데이터에서 각각의 타임스텝은 데이터 포인트(예를 들면, 시간 단위)를 나타냄\n",
    "- 3) SimpleRNN은 이전 타임스텝에서의 출력을 현재 타임스텝의 입력으로 사용함 따라서 timestep은 이러한 반복 프로세스를 얼마나 많이 수행할지를 결정합니다.\n",
    "\n",
    "2. input_dim (입력 차원):\n",
    "\n",
    "- 1) input_dim은 각 타임스텝에서의 입력 데이터의 차원을 나타냅니다.\n",
    " - For example\n",
    "  - 입력 시퀀스의 각 타임스텝에서 10차원의 데이터를 사용하는 경우 = input_dim은 10\n",
    "- 2) SimpleRNN은 각 타임스텝에서 이러한 입력 데이터를 처리하고 출력을 생성. 입력 차원은 모델이 데이터의 복잡성을 처리하는 데 중요한 역할\n",
    " - For example \n",
    "  - 텍스트 데이터의 각 타임스텝은 단어 벡터(10차원)이고, 입력 시퀀스는 2개의 타임스텝으로 구성된다고 가정합시다. 이 경우, input_dim은 10이며, timestep은 2입니다. SimpleRNN은 각 타임스텝에서 10차원의 입력을 처리하고, 이러한 두 타임스텝에 대한 출력을 생성합니다.\n",
    "\n",
    " - 따라서 timestep과 input_dim은 SimpleRNN 모델을 구성하는 데 필수적인 매개변수로, \n",
    " - 모델의 복잡성 및 입력 데이터의 형태를 결정\n",
    " - 이를 올바르게 설정하는 것은 모델의 학습 및 예측 능력에 중요한 영향을 미칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755c143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42 (168.00 Byte)\n",
      "Trainable params: 42 (168.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import SimpleRNN \n",
    "\n",
    "model = Sequential() \n",
    "model.add(SimpleRNN(3, input_shape=(2,10))) #2:timestep, 10:input_dim\n",
    "# model.add(SimpleRNN(3, input_length=2, input_dim=10))와  동일함. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c478f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(SimpleRNN(3, input_shape=(2,10))) #2:timestep, 10:input_dim 의 구조도\n",
    "\n",
    "#  Input (2, 10)\n",
    "#    |\n",
    "#  SimpleRNN (3)\n",
    "#    |\n",
    "#  Output (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80eda062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42 (168.00 Byte)\n",
      "Trainable params: 42 (168.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  return_sequences=False 인  경우 \n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import SimpleRNN \n",
    "model = Sequential() \n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2,10))) \n",
    "model.summary()\n",
    "\n",
    "# model.add(SimpleRNN(3, batch_input_shape=(8, 2,10)))의 해석\n",
    "# 1. SimpleRNN을 사용하여 3차원의 데이터를 처리\n",
    "# 2. input_shape에서 한번의 8개의 시퀀스 데이터를 처리할 수 있음\n",
    "# 3. (8, 2,10) - 2개의 timestep 과 입력차원은 10차원\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232bcb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import SimpleRNN \n",
    "model = Sequential() \n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2,10), return_sequences=True)) #  return_sequences=False 인  경우 \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecfd43",
   "metadata": {},
   "source": [
    "### RNN을  이용하여  텍스트  생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a560d0",
   "metadata": {},
   "source": [
    "### 1. 데이터에  대한  이해와  전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0553b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np \n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c40a8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"경마장에  있는  말이  뛰고  있다\\n 그의  말이  법이다\\n 가는  말이  고와야  오는  말이  곱다\\n\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e459bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의  크기  : 12\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer() \n",
    "\n",
    "t.fit_on_texts([text]) # Mapping 진행 \n",
    "vocab_size = len(t.word_index) + 1 \n",
    "print('단어 집합의  크기  : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "561462fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.text.Tokenizer at 0x20e95430700>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8410a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "print(t.word_index) # 각  단어와  단어에  부여된  정수  인덱스  출력- 빈도수 순으로 출력\n",
    "# index를 사용하지만 0은 사용하지 않음 따라서 1~11 로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2edd237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 1, 4, 5]]\n",
      "[[6, 1, 7]]\n",
      "[[8, 1, 9, 10, 1, 11]]\n",
      "[[]]\n",
      "학습에  사용한  샘플의  개수: 11\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for line in text.split('\\n'): # Wn을 기준으로 문장 토큰화\n",
    "    print(t.texts_to_sequences([line]))\n",
    "    encoded = t.texts_to_sequences([line])[0]  # texts_to_sequences 의 0번째 위치에 문장의 순서가 들어있음\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "print('학습에  사용한  샘플의  개수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c51051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences) # 전체  샘플을  출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff4d49e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의  최대  길이  : 6\n"
     ]
    }
   ],
   "source": [
    "max_len=max(len(l) for l in sequences) # 모든  샘플에서  길이가  가장  긴  샘플의  길이  출력 \n",
    "print('샘플의  최대  길이  : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68520b86",
   "metadata": {},
   "source": [
    "### pad_sequences\n",
    "`pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0) `   \n",
    "문장의 길이를 maxlen 인자로 맞추어 준다. 120으로 지정했다면 120보다 짧은 문장은 0으로 채워서 120단어로 맞춰주고 120보다 긴 문장은 120단어까지만 잘라낸다.    \n",
    "    \n",
    "- (num_samples, num_timesteps)으로 2차원의 numpy 배열로 만들어준다. maxlen을 120으로 지정하였다면, num_timesteps도 120이 된다.  \n",
    "- 인수\n",
    "    - padding : 'pre' or 'post'\n",
    "    - truncating : 'pre' or 'post'\n",
    "    - value : 채워질 값. default는 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe776fa",
   "metadata": {},
   "source": [
    "# pre가 쓰이는 경우 vs post가 쓰이는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431a9e5",
   "metadata": {},
   "source": [
    "pad_sequences 함수에서 'pre'와 'post'를 사용하는 선택은 데이터 및 작업의 특성에 따라 다를 수 있습니다. 각각의 사용 사례에 대한 고려 사항은 다음과 같습니다:\n",
    "\n",
    "1. 'pre' 패딩:\n",
    "\n",
    "(1) 언어 모델링: \n",
    " - 일반적으로 자연어 처리 작업에서 'pre' 패딩이 사용됩니다. \n",
    " - 문장의 시작 부분에 패딩을 추가하면 모델이 문장의 시작을 명확하게 구분할 수 있습니다.\n",
    "(2)시계열 데이터: \n",
    " - 시계열 데이터의 경우, 미래 값을 예측하는 모델을 만들 때 'pre' 패딩이 유용할 수 있습니다. \n",
    " - 모델은 미래 값을 예측하는 데 필요한 과거 데이터에 쉽게 접근할 수 있습니다.\n",
    "\n",
    "2. 'post' 패딩:\n",
    "\n",
    "(1) 텍스트 분류: \n",
    " - 텍스트 분류와 같은 작업에서는 'post' 패딩이 자주 사용됩니다. \n",
    " - 모든 문장이 동일한 길이로 맞춰지면 모델을 훈련하기가 더 쉽습니다.\n",
    " (2) 컨볼루션 신경망(CNN): \n",
    " - 'post' 패딩이 이미지 데이터를 다룰 때 일반적으로 사용됩니다. \n",
    " - 이미지 데이터의 크기를 일정하게 맞추기 위해 'post' 패딩을 사용합니다.\n",
    "\n",
    "3. 실생활 예시\n",
    "\n",
    "- (1) 텍스트 분류: \n",
    " - 영화 리뷰를 긍정 또는 부정으로 분류하는 작업에서 각 리뷰 문장의 길이를 동일하게 만들기 위해 'post' 패딩을 사용할 수 있습니다.\n",
    "- (2) 언어 모델링: \n",
    " - 문장 생성 모델에서 'pre' 패딩을 사용하여 시작 토큰(예: <start>)을 추가하여 문장의 시작을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3e4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "# 전체체  샘플의  길이를  6으로  패딩 \n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre') \n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca362cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences) \n",
    "\n",
    "X = sequences[:,:-1] # 학습  데이터 \n",
    "y = sequences[:,-1]  # 정답(Label) 데이터 print(X) \n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a502f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size) # 원-핫  인코딩  수행 \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22af390",
   "metadata": {},
   "source": [
    "### 2. 모델  설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd78238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2505a",
   "metadata": {},
   "source": [
    "#### Embedding\n",
    "`tf.keras.layers.Embedding( input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)`\n",
    "\n",
    "- 인수\n",
    "    - input_dim : 입력 크기\n",
    "    - output_dim : 출력 크기\n",
    "    - input_length : 입력 데이터의 길이\n",
    "\n",
    "단어를 밀집벡터로 만드는 일을 수행한다. 정수 인코딩이 된 단어들을 입력으로 받아 수행한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24f0eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 6)              72        \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 32)                1248      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1716 (6.70 KB)\n",
      "Trainable params: 1716 (6.70 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Embedding(vocab_size, 6, input_length=max_len-1)) \n",
    "model.add(SimpleRNN(32))  # SimpleRNN 오류발생하면 numpy 버전을 낮춤( pip install -U numpy==1.19.5) \n",
    "model.add(Dense(vocab_size, activation='softmax')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4ff0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 2.4900 - accuracy: 0.0000e+00 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4812 - accuracy: 0.0000e+00 - 0s/epoch - 0s/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4725 - accuracy: 0.0000e+00 - 17ms/epoch - 17ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4637 - accuracy: 0.0909 - 5ms/epoch - 5ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4549 - accuracy: 0.1818 - 0s/epoch - 0s/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4458 - accuracy: 0.2727 - 4ms/epoch - 4ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.4364 - accuracy: 0.4545 - 0s/epoch - 0s/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.4266 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.4165 - accuracy: 0.4545 - 0s/epoch - 0s/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.4058 - accuracy: 0.4545 - 17ms/epoch - 17ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3946 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3829 - accuracy: 0.4545 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.3705 - accuracy: 0.4545 - 17ms/epoch - 17ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.3575 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.3438 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.3293 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.3141 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.2981 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.2814 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.2638 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.2455 - accuracy: 0.3636 - 18ms/epoch - 18ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.2265 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.2067 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.1863 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.1653 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.1438 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 2.1220 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 2.0998 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 2.0775 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 2.0551 - accuracy: 0.3636 - 15ms/epoch - 15ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 2.0329 - accuracy: 0.3636 - 15ms/epoch - 15ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 2.0107 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.9888 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.9672 - accuracy: 0.3636 - 18ms/epoch - 18ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.9459 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.9250 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.9044 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.8840 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.8638 - accuracy: 0.3636 - 13ms/epoch - 13ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.8438 - accuracy: 0.3636 - 15ms/epoch - 15ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.8239 - accuracy: 0.3636 - 17ms/epoch - 17ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.8039 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.7839 - accuracy: 0.3636 - 17ms/epoch - 17ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.7637 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.7434 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.7228 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.7021 - accuracy: 0.4545 - 14ms/epoch - 14ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.6811 - accuracy: 0.4545 - 14ms/epoch - 14ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.6599 - accuracy: 0.4545 - 15ms/epoch - 15ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.6386 - accuracy: 0.4545 - 12ms/epoch - 12ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.6173 - accuracy: 0.4545 - 14ms/epoch - 14ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.5959 - accuracy: 0.4545 - 17ms/epoch - 17ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.5746 - accuracy: 0.4545 - 12ms/epoch - 12ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.5534 - accuracy: 0.4545 - 11ms/epoch - 11ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.5324 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.5116 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.4911 - accuracy: 0.5455 - 13ms/epoch - 13ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.4708 - accuracy: 0.5455 - 13ms/epoch - 13ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.4509 - accuracy: 0.5455 - 14ms/epoch - 14ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.4312 - accuracy: 0.5455 - 14ms/epoch - 14ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.4117 - accuracy: 0.5455 - 16ms/epoch - 16ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.3926 - accuracy: 0.5455 - 15ms/epoch - 15ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.3736 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.3549 - accuracy: 0.5455 - 15ms/epoch - 15ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.3363 - accuracy: 0.5455 - 18ms/epoch - 18ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.3179 - accuracy: 0.5455 - 15ms/epoch - 15ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.2996 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.2814 - accuracy: 0.5455 - 14ms/epoch - 14ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.2633 - accuracy: 0.6364 - 17ms/epoch - 17ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.2453 - accuracy: 0.6364 - 17ms/epoch - 17ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.2275 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.2097 - accuracy: 0.6364 - 3ms/epoch - 3ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.1921 - accuracy: 0.6364 - 14ms/epoch - 14ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.1746 - accuracy: 0.6364 - 16ms/epoch - 16ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.1573 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.1401 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.1230 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.1062 - accuracy: 0.6364 - 19ms/epoch - 19ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.0895 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 1.0729 - accuracy: 0.6364 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 1.0566 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 1.0404 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 1.0245 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 1.0087 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.9931 - accuracy: 0.7273 - 18ms/epoch - 18ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.9778 - accuracy: 0.7273 - 16ms/epoch - 16ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.9627 - accuracy: 0.7273 - 13ms/epoch - 13ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.9479 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.9332 - accuracy: 0.7273 - 20ms/epoch - 20ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.9188 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.9046 - accuracy: 0.7273 - 13ms/epoch - 13ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.8907 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8769 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.8634 - accuracy: 0.7273 - 17ms/epoch - 17ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.8501 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.8370 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.8240 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.8113 - accuracy: 0.7273 - 18ms/epoch - 18ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.7988 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7865 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7744 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7625 - accuracy: 0.7273 - 19ms/epoch - 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.7508 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.7393 - accuracy: 0.7273 - 20ms/epoch - 20ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.7280 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.7169 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.7060 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6953 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6847 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6744 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6641 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.6541 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.6441 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.6344 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.6248 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.6153 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.6059 - accuracy: 0.8182 - 1ms/epoch - 1ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5967 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5877 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.5787 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.5699 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.5612 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.5527 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.5442 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.5359 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.5276 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.5195 - accuracy: 0.8182 - 0s/epoch - 0s/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.5115 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.5035 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4957 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.4880 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.4804 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.4728 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.4654 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.4580 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.4507 - accuracy: 0.8182 - 19ms/epoch - 19ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.4436 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.4365 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.4295 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.4225 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.4157 - accuracy: 0.8182 - 13ms/epoch - 13ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.4089 - accuracy: 0.9091 - 15ms/epoch - 15ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.4022 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3956 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.3891 - accuracy: 0.9091 - 14ms/epoch - 14ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.3827 - accuracy: 0.9091 - 18ms/epoch - 18ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.3763 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.3700 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.3638 - accuracy: 0.9091 - 15ms/epoch - 15ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.3577 - accuracy: 0.9091 - 18ms/epoch - 18ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.3516 - accuracy: 0.9091 - 18ms/epoch - 18ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.3456 - accuracy: 0.9091 - 15ms/epoch - 15ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.3397 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.3339 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.3281 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.3224 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.3168 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.3113 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.3058 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.3004 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2951 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2898 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2846 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.2795 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.2745 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.2695 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.2646 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.2598 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.2551 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.2504 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.2458 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.2412 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.2368 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.2324 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.2281 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.2238 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.2196 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.2155 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.2115 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.2075 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.2036 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1998 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1961 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1924 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1888 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1852 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1818 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1784 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1750 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1718 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1686 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1654 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1624 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1593 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1564 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1535 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1507 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1479 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1452 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1426 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20e9303b0d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3aff3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옛날 버전\n",
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재  단어, 반복한  횟수 \n",
    "    init_word = current_word # 처음  들어온  단어도  마지막에  같이  출력하기위해  저장 \n",
    "    sentence = '' \n",
    "    \n",
    "    for _ in range(n): # n번  반복 \n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재  단어에  대핚  정수  인코딩 \n",
    "        print(\"encoded => \",encoded)\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에  대핚  패딩 \n",
    "        result = model.predict_classes(encoded, verbose=0) \n",
    "        print(\"result => \", result)\n",
    "        \n",
    "        # 입력한  X(현재  단어)에  대해서  Y를  예측하고  Y(예측한  단어)를  result에  저장. \n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 맊약  예측핚  단어와  인덱스와  동일핚  단어가  있다면 \n",
    "                break # 해당  단어가  예측  단어이므로  break \n",
    "        current_word = current_word + ' '  + word   # 현재  단어  + ' ' + 예측  단어를  현재  단어로  변경 \n",
    "        sentence = sentence + ' ' + word          # 예측  단어를  문장에  저장 \n",
    "\n",
    "    # for문이므로  이  행동을  다시  반복 \n",
    "    sentence = init_word + sentence \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5426387-f7cd-4680-baa8-9b8208a719fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded =>  [2]\n",
      "result =>  [3]\n",
      "encoded =>  [2, 3]\n",
      "result =>  [1]\n",
      "encoded =>  [2, 3, 1]\n",
      "result =>  [4]\n",
      "encoded =>  [2, 3, 1, 4]\n",
      "result =>  [5]\n",
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기 위해 저장\n",
    "    sentence = ''\n",
    "    \n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        print(\"encoded => \", encoded)\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict(encoded, verbose=0) \n",
    "        result = np.argmax(result, axis=-1)\n",
    "        print(\"result => \", result)\n",
    "        \n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어의 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "    \n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n",
    "\n",
    "print(sentence_generation(model, t, '경마장에', 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07a8f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded =>  [2]\n",
      "result =>  [3]\n",
      "encoded =>  [2, 3]\n",
      "result =>  [1]\n",
      "encoded =>  [2, 3, 1]\n",
      "result =>  [4]\n",
      "encoded =>  [2, 3, 1, 4]\n",
      "result =>  [5]\n",
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '경마장에', 4))  # 경마장에 다음에 나올 단어를 4개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00fcce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded =>  [6]\n",
      "result =>  [1]\n",
      "encoded =>  [6, 1]\n",
      "result =>  [7]\n",
      "그의 말이 법이다\n",
      "encoded =>  [8]\n",
      "result =>  [1]\n",
      "encoded =>  [8, 1]\n",
      "result =>  [9]\n",
      "encoded =>  [8, 1, 9]\n",
      "result =>  [10]\n",
      "encoded =>  [8, 1, 9, 10]\n",
      "result =>  [1]\n",
      "encoded =>  [8, 1, 9, 10, 1]\n",
      "result =>  [11]\n",
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '그의', 2)) # 2번 예측 \n",
    "print(sentence_generation(model, t, '가는', 5)) # 5번 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338fe042",
   "metadata": {},
   "source": [
    "### LSTM을  이용하여  텍스트  생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701012a2",
   "metadata": {},
   "source": [
    "### 1. 데이터에  대한  이해와  전처리\n",
    "•    파일  다운로드  링크  : https://www.kaggle.com/aashita/nyt-comments •    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5521f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from string import punctuation \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np \n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d44faba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('ArticlesApril2018.csv') # 데이터  로드 \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14d515ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의  개수:  15\n",
      "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
      "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
      "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('열의  개수: ',len(df.columns)) \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e483de74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].isnull().values.any() #null이 하나도 없으면 false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a823a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = [] # 리스트  선언\n",
    "headline.extend(list(df.headline.values)) # 헤드라인의  값들을  리스트로  저장 \n",
    "headline[:5] # 상위  5개만  출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb23ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총  샘플의  개수  : 1324\n"
     ]
    }
   ],
   "source": [
    "print('총  샘플의  개수  : {}'.format(len(headline))) # 현재  샘플의  개수\n",
    "\n",
    "# {}는 왜 썼을까?\n",
    "# .format의 의미는 무엇일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74a9dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈값  제거  후  샘플의  개수  : 1214\n"
     ]
    }
   ],
   "source": [
    "headline = [n for n in headline if n != \"Unknown\"] # Unknown(잡음) 값을  가진  샘플  제거 \n",
    "print('노이즈값  제거  후  샘플의  개수  : {}'.format(len(headline))) # 제거  후  샘플의  개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a7352a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5] # 5개의  샘플  출력  확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a90a2d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(s): \n",
    "    s=s.encode(\"utf8\").decode(\"ascii\",'ignore')  # from string import punctuation 사용\n",
    "    return ''.join(c for c in s if c not in punctuation).lower() # 구두점  제거와  동시에  소문자화 \n",
    "\n",
    "text = [repreprocessing(x) for x in headline] \n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e119019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어  집합의  크기  : 3494\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer() \n",
    "t.fit_on_texts(text) \n",
    "vocab_size = len(t.word_index) + 1 \n",
    "print('단어  집합의  크기  : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a30d4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습할 데이터 생성\n",
    "sequences = list() \n",
    "\n",
    "for line in text: \n",
    "    encoded = t.texts_to_sequences([line])[0] # 각  샘플에  대한  정수  인코딩 \n",
    "    for i in range(1, len(encoded)): \n",
    "        sequence = encoded[:i+1] \n",
    "        sequences.append(sequence) \n",
    "\n",
    "sequences[:11] # 11개의  샘플  출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa298aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7803"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ef1f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수  상위  582번  단어  : offer\n"
     ]
    }
   ],
   "source": [
    "index_to_word={} \n",
    "for key, value in t.word_index.items(): # 인덱스를  단어로  바꾸기  위해  index_to_word를  생성 \n",
    "    index_to_word[value] = key  \n",
    "\n",
    "print('빈도수  상위  582번  단어  : {}'.format(index_to_word[582]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "849462c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의  최대  길이  : 24\n"
     ]
    }
   ],
   "source": [
    "max_len=max(len(l) for l in sequences) # 가장  긴  샘플의  길이  확인 \n",
    "print('샘플의  최대  길이  : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d896484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "# 가장  긴  샘플의  길이인  24로  모든  샘플의  길이를  패딩 \n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre') \n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0634a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  99]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  99 269]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  99 269 371]]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences) \n",
    "X = sequences[:,:-1] # 학습 데이터 \n",
    "y = sequences[:,-1]  # 정답 데이터 \n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f7d80d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y[:3]) # 레이블  3개  출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16ef1650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size) # 레이블  데이터  y에  대해서  원-핪  인코딩  수행 \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089321d2",
   "metadata": {},
   "source": [
    "### 2. 모델  설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a966da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afdee5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 23), found shape=(None, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(vocab_size, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)) \n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filex_g2orl_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\isfs0\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 23), found shape=(None, 5)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "# y데이터를  분리하였으므로  이제  X데이터의  길이는  기존  데이터의  길이  - 1 \n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1)) # 10: 계산된 결과를 몇개까지 만들것인다\n",
    "model.add(LSTM(128)) \n",
    "model.add(Dense(vocab_size, activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c1c5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재  단어, 반복핛  횟수 \n",
    "    init_word = current_word # 처음  들어온  단어도  마지막에  같이  출력하기위해  저장 \n",
    "    sentence = '' \n",
    "    for _ in range(n): # n번  반복 \n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재  단어에  대핚  정수  인코딩 \n",
    "        encoded = pad_sequences([encoded], maxlen=23, padding='pre') # 데이터에  대한  패딩 \n",
    "        result = model.predict_classes(encoded, verbose=0) \n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 맊약  예측핚  단어와  인덱스와  동일한  단어가  있다면 \n",
    "                break # 해당  단어가  예측  단어이므로  break \n",
    "        current_word = current_word + ' '  + word # 현재  단어  + ' ' + 예측  단어를  현재  단어로  변경 \n",
    "        sentence = sentence + ' ' + word # 예측  단어를  문장에  저장 \n",
    "        \n",
    "    sentence = init_word + sentence \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "227750cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i cant jump ship from facebook yet sex and be near\n"
     ]
    }
   ],
   "source": [
    "# 임의의  단어  'i'에  대해서  10개의  단어를  추가  생성 \n",
    "print(sentence_generation(model, t, 'i', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb88ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to make an edge china sets a hard line on\n"
     ]
    }
   ],
   "source": [
    "# 임의의  단어  'how'에  대해서  10개의  단어를  추가  생성 \n",
    "print(sentence_generation(model, t, 'how', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c985a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
