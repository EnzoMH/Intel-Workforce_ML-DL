{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 라이브러리 가져오기"
      ],
      "metadata": {
        "id": "CCNzBCm-74SA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Iwy54MB9E5z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터 가져오기"
      ],
      "metadata": {
        "id": "bp4uKISL7_f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai_feeling = pd.read_csv('AI과정 느낌.csv', header=None, names=['feeling'])\n",
        "ai_lesson = pd.read_csv('AI과정 교훈.csv', header=None, names=['lesson'])\n",
        "\n",
        "app_feeling = pd.read_csv('앱과정 느낌.csv', header=None, names=['feeling'])\n",
        "app_lesson = pd.read_csv('앱과정 교훈.csv', header=None, names=['lesson'])\n",
        "\n",
        "print(ai_feeling)\n",
        "print(ai_lesson)\n",
        "\n",
        "print(app_feeling)\n",
        "print(app_feeling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "B07pUx8D_ODh",
        "outputId": "53b9138b-a887-4c26-f479-b19a0dac539b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f869604729f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mai_feeling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AI과정 느낌.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feeling'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mai_lesson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AI과정 교훈.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lesson'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mapp_feeling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'앱과정 느낌.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feeling'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapp_lesson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'앱과정 교훈.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lesson'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AI과정 느낌.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 데이터 전처리"
      ],
      "metadata": {
        "id": "se32Sc5g8CTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "column 이름이 같은 데이터 합침"
      ],
      "metadata": {
        "id": "eCPOp3bt8H4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_feeling = pd.concat([ai_feeling, app_feeling], ignore_index=True)\n",
        "df_lesson = pd.concat([ai_lesson, app_lesson], ignore_index=True)"
      ],
      "metadata": {
        "id": "4_CF_17XALtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "null 값 체크"
      ],
      "metadata": {
        "id": "i0wTulpO8Mnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_feeling.isnull().sum())\n",
        "print(df_lesson.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDOHrd75jtSu",
        "outputId": "305eb2e2-cf38-4b2a-d292-9cdc03ac0744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feeling    0\n",
            "dtype: int64\n",
            "lesson    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feeling = []\n",
        "feeling.extend(list(df_feeling.feeling.values))\n",
        "\n",
        "lesson = []\n",
        "lesson.extend(list(df_lesson.lesson.values))\n",
        "\n",
        "print(feeling[:5])\n",
        "print(lesson[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgGoT7-DkGYJ",
        "outputId": "2f6214a6-c751-4144-8226-6bf99015c143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['열심히 하자.', '오늘 실습 너무 쉬웠다. 역시 4조의 에이스는 나?', '오전에는 너무 어려웠는데 오후에 정리하면서 개념이 정리가 되어서 오늘 작성했던 코드가 다 이해가 되었다. 그래서 어려웠다고 생각했던 NLP에 한발짝 가까이 다가가게 된 것 같다.', '꾸역꾸역 따라가고 있다.^^', '실생활에 연계되거나 필요하다고 느꼈던 데이터에 직접 적용해보면 훨씬 집중된다']\n",
            "['아래분 보고 배워야겠다.', '자신을 내보여라. 그러면 재능이 드러날 것이다.', '다각도에서 생각하는 능력을 기르자.', '영화 리뷰를 내가 입력해서 긍정/부정 여부를 확인해 봤는데 ‘사이다’, ‘적토마’ 등의 어휘가 갖는 의미를 인공지능이 인식을 못했다. co-lab으로 올려봐서 학습시켜 보면 더 정확히 인식할 것이다.', '개발자의 의도에 따라 또는 실수로 인해 결과가 편향될 수 있으므로 주의를 기울여서 조건을 설정해야한다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# 정규표현식을 사용하여 특수문자를 제거하는 함수\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # 단어 문자와 공백 문자만 남김\n",
        "    return text\n",
        "\n",
        "# feeling 리스트의 각 문장에 대해 특수문자를 제거\n",
        "cleaned_feeling = [remove_special_characters(sentence) for sentence in feeling]\n",
        "cleaned_lesson = [remove_special_characters(sentence) for sentence in lesson]\n",
        "\n",
        "# 결과 확인\n",
        "print(cleaned_feeling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGyRqzxhmVaY",
        "outputId": "cfd2f968-8042-46c9-e595-9113caab8180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['열심히 하자', '오늘 실습 너무 쉬웠다 역시 4조의 에이스는 나', '오전에는 너무 어려웠는데 오후에 정리하면서 개념이 정리가 되어서 오늘 작성했던 코드가 다 이해가 되었다 그래서 어려웠다고 생각했던 NLP에 한발짝 가까이 다가가게 된 것 같다', '꾸역꾸역 따라가고 있다', '실생활에 연계되거나 필요하다고 느꼈던 데이터에 직접 적용해보면 훨씬 집중된다', 'NLP 과정중 영화 평을 분석해 그사람의 감성 이 긍정인지 부정인지 판단하는 프로그램을 만들었다 LSTM으로 학습했고 결과는 81로 맞는다 프로그램을 만들면서 pandas의 dataframe을 사용하면 굉장히 편할것 같은데 그걸 안쓰고 만드느라 좀 이해하기 어려웠다 덕분에 리스트 컨프리헨션에 대해 공부하게 되었다 모르는거 물어보면 다 답해주는 짝궁이 있어서 굉장히 이해가 잘되었다', '왜 이렇게 할 게 많은지 모르겠다 수업 내용 복습하고 정리하는 것도 빡세고 개인적으로 해야하는게 다 기한이 촉박하다 매일 늦게까지 남아서 하고 가는데도 시간이 부족하다 그리고 2인 1조로 하는거 좋은 것 같다 같이 고민하니까 평소보다 탄력받아서 진행하게 된다 근데 신문고는 갑자기 무슨일이지 \\xa0', '재즈 플리는 좋은데 인공지능 과정에서 듣기엔 기절하게 되는 포인트다 그래서 열심히 오프더레코드에 플리 올리고 있다 점심에 도우스피자 먹었는데 블루치즈앤베이컨이랑 버섯크림 짱맛 그리고 산책 너무 좋다', '깃 마스터 해야지 개발자 가자', '배우는게 좀 느리다', '차근차근 열심히 해야겠다', '여러가지를 동시에 하니까 과부하가 온 것 같다멍하다그렇지만 해야 한다 핵심 내용들은 꼭 짚고 넘어 가야지 나중에 힘들지 않을 것 같기 때문이다', '오늘의 실습으로 NLP 과정의 흐름이 어느정도 정리되는 느낌이었고 좀 더 개인적인 정리가 필요할 것 같다', 'NLP 들어와서 조금 멘붕이었는데 오늘 실습을 해보면서 쭉 정리할 수 있어서 너무 좋았다 근데 파이썬 문법에 익숙하지가 않아서 날코딩날코딩 할 일이 없다고 하더라도은 어렵다 list comprehension도 최근에야 겨우 직관적으로 이해하게 된듯 그래도 또 하나의 과정을 마무리했고 뭔가를 배웠다는 것이 뿌듯하다', '잠도 잘 못자고', '머리는많이 쓰고 피곤하다', '기분이 신난다 자몽향 핸드크림을 찾았다 향이 너무 좋아서 맡을 때마다 행복하다', '어찌보면 인간의 머릿속에서 언어를 표현하는 일련의 과정들을 컴퓨터로 입력하고 출력하려다보니 굉장히 어려운 과정이었던 것 같다 실무에서 FQ를 챗봇으로 설정하고 바로 상담사로 넘기는 이유를 알게 되는 좋은 학습과정이었던 것 같다', '요즘 무기력했는데 얘기를 듣고 괜춘해진 느낌', '절차 중심으로 코드리뷰를 하는 과정에서 배우는 시각적응성', '설치 및 세팅하느라 1시간 날려먹어서 킹받았다', '글치만 재빠르게 교육용 윈도우 노트북을 열고 파일 다운받아 수업을 따라올 수 있었다', '윈도우는 애증의 운영체제인듯', '오늘 진도를 조금 천천히 나가게 되어 흐름을 다시 한 번 되짚어 볼 수 있었다 내가 원하는대로 적용하기까지는 시간이 많이 걸리겠지만 계속 도전해봐야겠다', 'NLP가 이미지 처리보다 더 재미있다 어렵지만 복습 꾸준히 하도록', '근데 오늘 먹은 라떼가 카페인이 너무 높아서 오후시간이 힘들었다', '반성하고 디카페인 먹도록', '딥러닝의 동작 원리를 이해가는 중', '5일 만에 성찰일지를 적었다 아파서 못나왔는데 그동안 진도가 은근히 나간 것 같다 내용은 어려운데 빠르게 넘어간다 복습을 하고 싶지만 할 게 많당', '내일 하는 오늘 했던거 이어서 할거같다 너무 설레고 기대된다', '코드를 조금씩 알다보니 신기하다', '어렵지만 이해가 필요할 것같다', '열심히 하자 대거 히트 레스트 api 개발자 기술스택', '이해가 안가는 부분을 더욱 공부를 열심히 해야겠다', '못 해 본 건 아쉽지만 해본 거는 꼭 숙지하기', '복습을 열심히 잘해야겠다', '이해가 안되는 부분도 생기는것 같다', 'GPT활용 능력이 발달하는 느낌', 'NLP는 어려운것같다 이제 토큰이라는 것을 알게 된것 같다 그리고 RNN을 하면서 시퀀스에 대해 알게 되었고 알고리즘이 좀 신기 한것 같다 그거와 별개로 데이터 전처리가 제일 어려운 작업인 것을 깨달았다 신기하게 그렇게 졸리지 않은 날이었다', '호텔 안내 챗봇을 만들 때는 개념이나 많은 것들이 그냥 떠있는 느낌이었는데 오류가 나서 재야의 은둔 고수님께서 오류를 고쳐주시는 과정에서 모든 것이 재정립되면서 이해가 확 되었다', '오늘 코사인 유사도 호텔 챗봇 제인 만들기랑 LSTM RNN을 배웠는데 각 단계에서 이전 단계의 출력을 재귀적으로 활용한다는게 재밌었다', 'padding을 왜 하는지 각 단어 별로 정수 인덱싱을 하는 규칙은 무엇인지 짝꿍이랑 모르겠는 부분 얘기하면서 실습하니까 꺾이지 않을 수 있었다', '신경망 코드 설명해주실 때 마다 고비가 온다 너무 정신이 혼미하다', '단계 마다 왜 이걸 하는지 이해하고 넘어가야겠다 하루 하루 할 일이 넘쳐난다ㅏ맛있는 걸 먹고 버티자', '어제 나올걸 그랬나싶었다', '솔직히 무슨 말인지 1도 모르겠다 너무 피곤하다', '항상 어려움을 느끼지만 수업 후에 내가 하루 배웠던 것을 되짚어보면서 내가 이런 어려운 것을 늘 해내 왔구나 라는 생각이 들면서 그 다음 날 더 어려운 것을 배운다는 것에 대한 걱정보다는 기대감이 더 커진다', '스트레스', '으어어', '오늘은 집가서 푹쉬고 놀 계획이었으나 이해되지 않는 RNN으로 인해 야자', 'RNN도 마스터해보자', '수 목은 조퇴니까 오늘 열심히 했다', '복사 붙여넣기 cmdC cmdV 는 확실하면서도 마약 같다 직접 타이핑을 안하고 복붙에 의존하는 느낌 때문에', '자꾸 예전 걸 까먹어 pdread_csv너무 오랜만', 'nlp가 제일 어려운 것 같다 그래도 오늘 특별 짝궁의 도움으로 조금 더 이해할 수 있었다 냠냠', '성급하지 않게 조금씩 천천히', '집중하고 싶다 집중이 안됌 ㅠ', '오늘보다 내일 더 열심히 하자', '파이썬에 좀 더 익숙해져야 할 것 같은 생각 챗봇을 만들어보았다는 점 자체에 대한 뿌듯함 다양한 라이브러리 사용이 신뢰감을 만든다', '오늘 오후에 날씨가 울적해서 수업 집중이 잘 안됐다 그래도 실습은 재미있었다 마지막 실습 때 코드를 가져와서 하다 보니 또 변수를 잘 못 적는 오류를 냈는데 스스로가 너무 한심했다', '자연어 처리 및 인공지능 분야는 지속적인 학습이 필요합니다', '속도감이 느껴지는 학습이었던 것 같고 셀 코딩으로 블록이 흩어져있는 느낌 정리가 필요할 것 같다', ' 맨정신이 아닌데 수업 시간에 집중이 엄청 잘 되네 뭐지', ' 주말에 폭식을 하고 돌아왔더니 살이 3kg 빠져 있다 뭐지', ' 나갔다 돌아왔더니 일상이 특별해졌다 너무 좋다 ', '어렵습니다', '코드를 따라 써보며 세세한 부분에 대한 이해는 힘들었고 흐름만 대충 이해를 했다 내가 배우는 것들을 어떻게 활용할 수 있는지 생각해보고 테스트해봐야겠다', '컨디션이 안좋아서 강의에 집중을 못한것 같다', '깊은 학습과 지속적인 노력이 현실적인 결과물을 만들어내는데 얼마나 중요한지를 깨달았음', '떡볶이 먹었다 맛있었다', '주변 사람들의 도움을 통해 챗봇을 만드는 과정에 흥미를 느꼈다', '컴퓨터는 역시 멍청하다', '오늘 코드를 보면서 어떻게 동작을 하는지 위에 주석을 달고 하나하나씩 써가면서 들었다 그러다보니 어느순간 놓쳐서 중간부터 못하고 그냥 들었다 라이브러리를 이용해서 엄청나게 복잡한 코드를 한줄로 사용하는 것은 너무 편한 것 같다 그 전에 했던 작업들이 이걸 왜 했지 할정도로 좋다 하지만 이해를 돕기위해 한번씩 해보는 것이기 때문에 그냥 코드로 짜보는것도 괜찮은 것 같다 노트북 거치대를 사용하니 왼쪽손이 아픈데 뭐지 저번주엔 오른손아팠는데 교대로 아프네', '흐름을 잘 이해하고 코드 한 줄 한 줄 어떤 의미인지 제대로 이해하는 것이 중요한데 많이 부족하다 2개월만 잘 버텨보자 할 수 있따', '전에 그냥 간단하게 만들었던 챗봇이랑 비슷해서 신기했다', '월요일이 너무 피곤하다', '집중이 잘 안됨', '드디어 자격증 시험 끝나고 첫 날 너무 열심히 집중해서 피곤함이 싹 몰려왔다', '코사인 유사도는 뭔가 반가운 부분이라 더 열심히 코드를 이해하고 내가 만들고 싶은대로 챗봇을 만들었다 신경망은 볼 때 마다 익숙한데 새롭다', '인공지능 과정 2주도 안남았는데 수업 열심히 듣고 복습하고 내껄로 만들어야겠다', 'tmi요즘 왜 이렇게 떡볶이가 당길까 떡볶이를 매일매일 먹어도 한결같이 맛있음을 느낄 수 있을 것 같다 오늘 떡볶이집에 가서 김밥 떡볶이 튀김 순대를 먹었는데 어떻게 배가 부른데도 맛있어서 계속 먹게된다 여기 근처 떡볶이 먹으러 투어를 가고싶다 떡볶이 투어모임 만들었다 주기적으로 갈거다', '머리아파서 타이레놀먹으며 열심히해서 잘했다', '모든 팀원이 출석했다', '배고프면 집중할 수가 없다 배불러도 집중할 수가 없다 나는 배고프다', '나는 졸리다', '오전 챗봇만들기는 인삿말 만들기종료말 을 함수로 만들어서 진행했다 어쩐지 상호작용은 잘 안되는 듯 싶었다 기존 챗봇서비스에서 대답할 수 없는 부분은 상담사와 연결하는 방식을 API로 활용하는 걸 이해했다', '내일이 시험이라 오늘 실습 빨리 끝내고 공부 할려고 했는데 실습이 너무 어렵고 오래 걸려서 자격증에도 수업에도 꺽였다 오류가 계속 나는데 오류 잡는 게 감이 안 온다 전에 비슷한 말을 최재흥 개발자님께 여쭤봤지만 경험치문제라고 하셨다 하지만 경험치 언제 쌓지', '계속 에러사항이 되서', '생각보다 원인을찾는데 오래걸렸다', '눈에 익히기  숙지가 됨', '오늘도 자연어처리 관련해서 코딩 실습을 했고', '다음주 챗봇 만드는 실습이 기대가 된다', '실습을 통해 실제 데이터에 대한 처리와 모델링을 직접 수행하면서 더 깊은 이해를 얻을 수 있었', '개인 노션으로 파일들을 옮기자 모두들 세굿바', 'NLP로 넘어왔는데 순서와 흐름을 잘 이해하고 파악해서 다른 데이터로도 할 수 있도록 공부하는 것이 좋겠다 10월11월 잘 버텨야지', '오늘 수업 과제정리를 하면서 에러는 나지 않았지만 실행되지 않았던 코드들이 많아 지우고 다시 시작해서 시간이 오래 걸렸다 일지에 작성한 사실 내용을 바탕으로 쭉 훑어볼 필요가 있다', 'tmi점심 후 이웃조원 두 분께 체조시간에 보여드릴 춤 리허설을 했다 오늘 준비한 동작은 전날보다 어려운 동작들이 들어가서 다양한 분들께 리허설을 그동안 많이 보여드렸다 그렇게 땀 흘리고나니 금방 추워졌다 감기를 조심하자 오늘 그 두 분께 유고걸을 살짝 보여드렸는데 체조에서 이제 춤으로 넘어간 것 같다고 좋아하셨다 운동동작 많이 넣을거예요', '수업 내용을 거의 이해하지 못했다 비는 시간을 활용하여 실습을 해보고 내용을 따라가야겠다', ' 확실히 뭔가를 알고 들어가니까 아침부터 공부가 너무 잘 되서 기분이 좋음', '심지어 날씨까지 좋아서 더 좋음 점심밥 비빔밥 맛있어서 더더 더 좋음', '중앙 자리에 앉으니까 집중이 잘된다', '오전에 한국어 데이터 처리를 한 것 같은데 나는 이걸 건너 뛰었다 파이선으로 형태소 분석을 하다니 알아두면 좋을 것 같다', '열심히 수업을 듣다가 4시 이후에 갑자기 너무 졸음이 밀려와서  코드를 겨우 돌렸다 25예제는 이따 다시 돌려봐야할 것 같다 그리고 오늘 비와서 기분 좋았다', '처리 과정과 순서를 제대로 이해하고 가야겠다 코드 마다 어떤 것을 의미하는지  쭉 정리를 하는 시간을 가져야겠다  중간 중간에 코드를 찍어보면서 어떤 값이 나오는지 확인해야지', '아 늦었어 나', '할로윈 소품 분장 찾아보았다', '자연어 처리하는 과정 복잡하지만 신기했다', '뭔가 더 있을 것 같은 자연어처리 세계 어디까지 있을까 들어가 볼까봐', '토큰화부터 시작해서 TFIDF 배열로 모델 훈련시키는 부분까지 해보는 것이었다 아직 BOW랑 TFIDF 코드흐름을 제대로 이해 못해서 조금 더 공부해야지 stopword 제거랑 stemming lemmatization까지는 이해한 것 같다 역시 이 부분도 adp 내용과 겹쳐서 수업 들을 때 낯설지 않았다', '다가오는 알고리즘을 풀어야 하는데 자격증 때문에 토요일부터 해야할 것 같다 그리고 수업 복습을 소홀히 했기 때문에 날잡고 수업 내용 정리하면서 자연어처리까지 공부해야겠다', '해커톤을 위한 서치무한 자료조사 그리고 해보기 일요일이 오기 전까지 해놓아야 한다 나 왜 이렇게 할 게 많은거지', '점심 먹으면서 이터널션샤인 비포선라이즈 시리즈 추천을 받았다 토요일에 볼려고 했는데 어시간이언젠가 봐야겠다', '첨으로 멘붕옴 컨디션 난조도 있는데 내용 자체가 너무 어렵당 ㅠ ㅠ tfidf 전처리하고 뭐 그건 알겠는데 hashmap써서 bag만들고 물론 이걸 날코딩 할 일은 없다고 하셨지만 뭔가 마음속깊이 와닿지 않았다 왜일까 얠 뭘 어떻게 할 수 있는지 감이 안온당', 'NLP를 어떻게 해야하는지 잘 모르겠다', '수요일인 줄 알았는데 목요일이라니', 'NLP를 어떻게 처리하는지 간접적으로 확인 할 수 있어서 재미있었다', '오랜만에 데이터 전처리를 하니깐 리셋 되었따 분명 어간추출하고 금지어 제거하고 이런거 하다가 갑자기 데이터 전처리를 시작하니 막혔다 이후 내용은 이해하지 못해서 시간내서 복습을 해야겠다 정말졸린 하루였다', '잘 자고 와야겠다', '오늘은 코드가 잘 안된다  에러가 변수다   이해가 잘 안된듯 하다', '중간에 집중력이 너무 흐트러져서 많이 놓쳤는데 다시 마음 다잡고 처음부터 다시 코드를 훑어보았다 그래서 대충 이해가 되고 수업을 다 따라잡은 느낌이 들었다 집에 가서 복습하면 오늘의 수업이해도가 만족스러워질 것 같다', '실습예제 오늘은 뭔가 집중이 안되는 느낌이었다', '처음하는거라 쉽지 않다', '늦게왔지만 조원의 도움으로 jdk설치도 하고 자연어처리도 공부했다 아주잘했다', '토큰화에 대한 예제를 보면서 국어를 공부했을 때가 떠올랐다 하나의 주어진 문장을 구성하고 있는 형태소 분석하기에 관련된 문제들을 풀었었는데 우선 띄어쓰기가 되어있는 상태를 확인하며 단어를 분석하고 분석한 단어들을 구성하고있는 어간 어미종결어미 선어말 어미를 세부적으로 분석하고 실질 형태소와 형식 형태소로 분류하고 그렇게 쪼개고 쪼개는 과정을 통해 재밌게 문제들을 풀었었던 기억이 떠올랐다 이렇게 수업을 통해 그동안 공부했었던 다른 공부과목도 연관지어 생각할 수 있는 기회가 좋았다', 'tmi체조시간을 준비하면서 리허설을 틈틈이 하는데 보통 로비나 복도쪽에서 리허설을 하곤한다 로비에 여러 사람들이 있는 경우엔 복도로 이동하지만 한두 명만 있을 경우엔 그냥 무시하고 춤춘다 나의 춤을 봤던 로비 사람들도 행복했으면 한다 나의 리허설을 항상 챙겨보며 좋아해주시는 이웃조원분이 계시는데 그 분 외에도 무슨 춤을 준비해왔는지 궁금해하는 분들이 많이 계셔서 춤을 추고싶은 느낌이 딱 온다싶으면 무작위로 뽑은 몇명을 데리고나가 복도 의자에 쪼르르 앉혀놓고 리허설을 보도록 하는 서비스를 제공하기 시작했다 자기를 뽑고 데려나가달라고 하는 분들도 생겨서 기쁘다 후후', 'tmi리허설을 열심히 하고있는데 지나가다 우뚝 서서 계속 무섭게 지켜보시는 분이 있다 부끄러웠고 그분께 완성이 덜 된 춤을 보여드리기엔 자신이 없어서 가줄래 하고 부탁드렸다 ', '흥미가 있었다 wordcloud 부분 실행이 되지 않는데 폰트 문제인지 버전 문제인지 모르겠다 이 부분을 해결하고 집에 가야겠다', '이전과는 다른 방식으로 진행되는 수업에 약간의 버거움이 있는것 같다', 'AI과정 첫날이다 첫 시작이라 많이 힘들긴 하지만 팀프로젝트 때 잘 활용할 수 있도록 열심히 해야지', '쉬는시간이 너무 짧다 롱런을 위해서 텀이 짧거나 조금 더 길었으면 좋겠다', '새로 뽑힌 팀의 분위기가 좋다 나는 3번 연속 같은 자리인데 사람들이 바뀌니 더 재미있어지는 듯 하다', '이론 교육은 간만이라 확실히 집중이나 적응하기는 어려웠고', '관심있는 인공지능에 대해 배워서 흥미롭게 들었다', '퍼셉트론 AI예시모델과 Teachable Machine 모델 그룹 만들 때 팀원분들과 같이 만들었는데 재밌는 경험이었다', '오늘 AI 첫수업을 시작했는데 9월 새로운 달을 시작하는 의미에 대해 생각해보니 열심히 보낸 하루가 알찼다 오후 수업을 듣다 피로감이 누적돼서인지 자꾸 눈이 감겼지만 오전에 만들었던 Replika AI 아바타를 보면서 졸음을 버텼다 내가 만든 아바타를 보고 많은 분들이 좋아해주셔서 뿌듯했다', '막연한 AI 서서히 실체를 마주할 것 같은 기대', '3번째 팀 트윅스와 함께 아름다운 여정을 만들어야 겠다', '팀 원들과 다같이 짧은 시간 안에 으쌰으쌰한 좋은 경험 형준님과 종대님이 한턱씩 쏘셔서 멋진 마무리', '팀 프로젝트를 하면서 많은 것을 느꼈다 자소서에 소중한 한 줄이 될 거 같다', '처음에는 짧은 시간안에 과연 팀 프로젝트를 마칠 수 있을까 하는 생각도 들었는데 그동안 팀원들이 각자 맡은 분야에서 최선을 다해 노력하니 드디어 팀 프로젝트를 무사히 완료할 수 있었다는 점에 기쁨과 안도감이 들었다', '또한  처음에는 내가 과연 필요한 기능을 구현을 할 수 있을까 하는 걱정도 앞섰는데 결국은 완성할 수 있어서  팀에 도움이 될 수 있어서 그리고 내가 맡은 몫을 스스로 해낼 수 있어서 뿌듯했다', '팀프로젝트 7일이 참 빨리간것 같다  앱개발을 같이 해보니 개인프로젝트보다 훨씬더  어려움도 많았다', '같이 작업한 팀원들이 너무잘해서', '도움을 많이 받았고 덕분에 실력이 향상된것 같아서 뿌듯하다', '팀원들 모두 수고하셨습니다', '각자의 역량을 발휘했고 짧은 시간 기품있는 프로젝트 완주를 위해 배려와 양보가 있었기에 가능했다고 생각합니다', '새롭게 도전해 본 분들도 있었고 아쉽지만 팀에 도움이되는 역할에 충실했던 분들도 있었죠 앞으로 AI과정도 기품있게 완주해요 모두 응원합니다', '함께해서 좋았습니다 감사드려요', '길다면 길고 짧다면 짧은 안드로이드 앱 개발의 첫 팀 프로젝트가 마무리 되었다 1주일동안 같이 함께 작업한 우리 팀원들 다 최고다 2달동안 배운 안드로이드 앱 개발 과정이 끝나는 날이기도 했다  그동안 많은 것을 가르쳐 주신 강사님 고생많으셨습니다  더이상 안드로이드 앱 개발 과정이 아닌 것이지 다른 과정은 남아있다 그래도 앱개발은 하면서 결과를 바로바로 볼 수 있어 재미있었다', '첫번째 팀 프로젝트가 끝났다 첫번째 팀 프로젝트의 앱 개발 동안 실질적으로 개발을 한 게 없어 개인적으로 아쉬움이 든다 모두 내 역량이 부족해서 그런 것 같다 내 몫까지 다른 팀원들이 해주어서 좋은 결과물이 나온 것 같다 여럿이 한팀을 이루어 성과를 달성하는 좋은 경험이었다 다음 팀 프로젝트를 수행할 때는 더 향상된 역량을 바탕으로 팀 프로젝트에 기여할 수 있었으면 좋겠다', '기한이 정해져있는 상황에서 고군분투를 하는 과정을 겪으면서 돌아보니 뭔가 내 자신도 성장한 느낌이 들어서 뿌듯하기도 하고 굉장히 힘들어서 다시 이런 스케쥴을 소화할수있을까 걱정이 되기도 한다 어찌됬든 이제 푹 쉬자', '팀원 모두가 네 일 내 일 구별하지 않고 서로 도우면서 과제를 완성하는 모습이 너무 좋았다 아쉬움도 남고 후련하기도 하다', '처음 팀프로젝트를 시작했을 때 어떻게 진행해야할지 막막했는데 막상 일주일동안에 진행되었던 일정이 마무리가 되니까 시원섭섭한 기분이 느껴졌다', '그래도 오늘은 마지막 날 이라 팀원들과 단체로 점심도 먹고 어제 밤에 남아서 같이 프로젝트 마무리도 하고 해서 기분이 좋다  ', '이번 프로젝트를 통해서 다양한 분들의 경험치들을 옆에서 배워가며 나도 성장할 수 있었던 시간이 되었다', '기회가 된다면 많은 프로젝트들을 통해서 실력이 커갈 수 있는 시간을 많이 확보해야겠다고 생각이 들었다', '팀원들과 같이 협동하며 하나의 앱을 만들어가는 과정이 은근 재미있었다 계속 앱 개발 조금씩 만져보고 싶다', '시간이 벌써 이렇게 흘렀다는 사실이 믿기지 않을만큼 빠르게 지나갔다 앱 개발 과정을 통해 정말 많은 것을 배웠고 머릿 속에만 있던 지식들을 프로젝트까지 작업하면서 공부 방향도 함께 잡힌 것 같다 한 번의 사이클을 경험한 것을 토대로 앞으로도 개발 공부를 열심히 해야겠다 그리고 고생한 모든 교육생들과 함께 열심히 해준 팀원들에게 너무 고마웠다 인공지능 과정도 모두 화이팅했으면 좋겠다', '드디어 팀프로젝트가 끝났다 개인 프로젝트 보다 부담감이 심해서 걱정 많이 했는데 좋게 마무리 되서 다행인것 같다 정말 많이 배우고 정말 많이 느낀 한주였다 팀원분들이 다들 너무 잘해주셔서 좋게 마무리 한 것 같다', '프로젝트를 진행하면서 한 작업정도는 내가 끝까지 마무리하고 싶었는데 그러지 못해 아쉽다  혼자 API랑 다양한 기술이나 라이브러리들 활용해봐야겠다는 생각이 들었다 그리고 오늘 쉬는시간에 포트폴리오 많이 찾아봤는데서 아직까지도 감이 잡히지 않는다 계속 써보고 찾아봐야겠다', '어제 저녁에 피피티 발표 피드백을 선생님께 받으러 가기 전엔 발표를 잘 할 수 있을거라 생각했지만 발표를 시작했을 땐 표현하고자 하는 어휘들이 떠오르질 않아 자신감도 떨어지고 팀원분들께 미안한 마음을 느끼게되었다 피드백을 받고 난 후 피피티를 함께 수정하고 퇴실하기 전 발표를 맞춰보았는데 좀 더 발전한 느낌을 받았다 내일은 더 잘 할 거야 하고 긍정적인 생각을 하며 잠이 들었는데tmi', '꿈 속에서 퉁퉁한 아저씨가 옆에서 발표를 가만히 듣다 구겨진 얼굴로 눈으로 욕하면서 피피티 화면을 번갈아보며 나를 혼냈다 사실 이 아저씨는 방시혁 아저씨다 이 분이 왜 내 꿈에 나오신진 모르지만 꿈과 현실은 반대니깐', '팀프로젝트와 동시에 8월도 끝났다 다행히 팀워크가 잘 되서 마무리도 나름 좋았다 맡은 역할에 최선을 다했지만 과정 및 결과에서 이렇게 했다면 어땠을까 하는 1 정도의 아쉬움은 있다', '다만 앱 과정이 끝나더라도 연습은 놓지 않을 생각이다 기술 하나 배운 셈인데 놓을 이유는 없지 않을까', '프로젝트가 끝나서 기분이 너무 좋고 푹 쉬어야지', '팀 프로젝트가 잘 마무리가 되어서 다행이다 구현하고 싶었던 기능들이 더 있었는데 시간이 부족해서 전부 구현하지는 못했다 개발을 하다가 처음에는 잘 안되고 힘들었다 그래서 강의 시작하고 처음으로 재미없다고 느껴졌는데 내가 맡은 부분이 성공되었을 때 엄청 기쁘고 이래서 개발을 하는 거구나 라는 생각이 들었다 팀원들이 너무 잘 해서 내가 맡은 부분에만 집중해서 할 수 있었다 그런 부분에서는 팀원들에게 미안한 느낌이 들었다', '팀프로젝트가 잘 마무리되었다고 생각하고 명호님이 어제발표자료를 만드시고 목 컨디션이 안좋은 상태에서 발표까지 하셔서 정말 고생하셨다고 생각한다', '강사님과는 마지막 날이기에 우리들의 이벤트가 있었고', '마지막이라니 아쉽다 강사님께 특히 개발자로서 가져야하는 것들에 대한 전체적인 튜토리얼을 배운 것 같아서 좋았다고 생각한다', '여러가지를 경험할 수 있는 팀프로젝트였다', '앱 과정이 마무리 되었다 2개월 가량 많은 것들을 배웠는데 이번 팀 프로젝트가 2개월 과정의 마무리라고 생각하고 최대한 열심히 하려고 했었다 팀원을 잘 만나서 짧은 기간 동안 구현한 기능들이 꽤 많았고 앱 과정을 만족스럽게 마칠 수 있어서 다행이라고 생각한다', '폴바셋 받아서 신난다', '팀 프로젝트 최종 완성을 하면서 PPT 및 발표자료가 오늘로 완성되었습니다 개인프로젝트보다 훨씬 힘든 작업이 될 것이라 예상은 했었지만 생각보다 더 힘들었다 코드를 짜는  시간보다도 각자 짠 코드를 합치는데 더 오랜 시간이 걸렸다 그런데 계속 코드를 짜다보니 욕심이 생겨 더 기능구현을 하다가 계속 늦어지게 되었다 그러다보니 기획과 PPT만드는 과정이 늦어졌다 느낀 건 기획 단계에서 충분한 토론이 이뤄져야 한다 또 계속해서 기능 구현을 팀원을 적당히 구슬려서 디자인을 하게 만들어야겠다고 생각했다 기능 구현하다가 디자인할 시간이 너무 모자랐기 때문이다', '팀 프로젝트가 마무리되어서 후련하고 뿌듯하다', '처음으로 협업을 해 보았는데 어려운 점도 많았지만 좋은 팀원들 덕분에 완주할 수 있었던 것 같다 공사가 다망한 우리 팀이었지만 여러 제약 속에서도 무언가를 구현해 냈다는 것이 뿌듯하고 나도 그 과정에서 코딩 뿐 아니라 정성적인 부분들도 많이 성장한 것 같아서 개인적으로 좋은 프로젝트였다고 생각한다 끝날 때 까지 끝난 것이 아니니 계속해서 마음을 다잡으면서 완주하자 기품있게', '빨리 끝날 줄 알았는데 진척이 없어서 힘들었다', '그래도 팀원들과 함께 끝내서 후련하다', '어제부터 그룹웨어 시스템 구축 프로젝트 마무리 하느라 수강생분들이 많이 고생하셨는데 드디어 끝이 났다 팀플 진행하면서 배운점도 많고 느낀점도 많고 깨달은점도 많다 5팀 식스아이 너무 고생하셨고 기대 이상인 것 같아서 너무 좋네요 마지막 점심과 카페형준종대님 감사드리며 준호은진명호님도 너무 고생하셨습니다ㅠㅠ 그리고 오늘 앱과정 마지막이라 강사님과 질의응답 시간도 갖고 서프라이즈 시간도 가졌다 아쉽다ㅜㅠㅠ진짜임패션F 아님', '드디어 끝났나 와', '힘들지만 다왔기에 파이팅', '체력이 딸리는 느낌이 들어 12시간 정도 손해본 느낌이었다 하지만 팀프로젝트의 끝이 보이고 막판 스퍼트를 화려하게 장식해볼까 한다 파이팅', '어제부터 뭔가 한 건 없는데 버그 잡아내고 디자인 작업하고 서서히 머지 시작했다 역시나 버그는 계속 발생하고 머지라고 하기는 애매하지만 수동으로 머지하는 과정에서 핵심 기능이 작동을 안해서 해결해야한다', 'git 사용 너무 어렵다 공부 해야지', '너무 빠듯하다 아마 이중Array 문제와 데이터양 때문에 파이어베이스 스토리지는 못쓸지도 모르겠다는 생각이 들었다 개인 페이지 기능이기에 room으로 방향을 틀어야 할지도 모르겠다', '오늘 하루가 지날 수록 점점 마음이 급해졌다 그래서 몇 가지 놓쳤는데 팀원이 도와주었다 어쨌든 오늘 개인 대화 기능 구현에 성공해서 마음이 놓였다 이제 팀원들을 볼 낯이 생겨서 다행이다', '결국 끝이 다가오면 어떻게든 끝낼 준비가 되기 때문에 어제 걱정이 무색하게 뭔가 완성이 된 것 같다 팀원들 고생해줘서 너무 고마운 것 같다', '팀 프로젝트 기간이 짧다고 생각했는데 팀원들이 다들 각자 맡은 부분에 최선을 다 해줘서 끝이 보이기 시작한다 이제 디자인을 해야 하는데 자신 없지만 열심히 해야지', '진짜로 정말로 GitHub든 코드복붙이든 merging 자체가 쉽지 않은 걸 팀원을 보면서 느꼈다', '코드도 함부로 건드리지 못하겠고', '뭔가 오늘 뭐했는지 기억이 안난다 어제 너무 늦게 자서 졸리다 뭔가 끝이 보이기 시작한다 내가 맡은 부분은 나는 기능적 부분을 더 추가하고 싶지만 시간이 나를 붙잡는다 아쉬운 마음이 있다', '에러의 밭에 빠진듯 하다  오늘은 무조건 성공해야되는데 걱정이다', '강사님의 도움으로 수정 및 삭제 기능을 구현할 수 있었다 나머지 이미지 기능과 화면 구성을 수정해야 하는데 시간이 많이 남지 않았기 때문에 어떻게 할 지 고민이 된다 최대한 할 수 있는 데까지 빌드 에러 없이 마치고 오늘 안에는 merge하고 프로젝트를 끝내야 한다', '개인 프로젝트 끝나고 바로 시작한 팀프로젝트라서 많이 힘들지만 팀원 끼리 협업을 하는 과정이 즐겁다', '어렵지 않은 기능이지만 시간이 좀 걸리는 것 같다', '프로젝트 설계 시 데이터 및 통합작업를 고려했기에 비교적 혼선이 적었던 것 같다', '깃 활용을 고려했으나 짧은 일정에 깃활용법에 관한 학습과 가이드까지 소화하기에는 어려움이 있었다  다음 협업 시는 깃활용이 필수일 것 같다 소스 이전 및 설정 등 깃의 잇점이 있기 때문이다', '짧은 프로젝트 기간에 각자 역할에 충실했기에 기품있게 완주하기 가능한 것 같다', '개인적으로 많은 프로젝트를 경험했지만 개발자로 참여하여 프로젝트 디렉팅은 처음이라 의미 있는 경험이다', '골드스푼 화이팅', '어제까지만 해도 막막했던 채팅기능이 작동하니까 기분이 너무 좋다', '어제와 오전 전자서명 기능 구현 코드를 만드는 과정에서 에러가 사라지지 않고 나아지질 않아서 계속 고민하다 선생님께 조언을 구헸다', '선생님께서도 내가 접근한 방식은 안 해본 방식이라며 다른 자료들을 찾아주셨다 선생님의 도움으로 다행히 전자서명 기능을 구현하는 과정이 이해되었고 추가적인 기능도 생각해보았다', '이제 코드들을 팀원분들과 합치고 디자인을 마무리해야하는데 핸드폰 연동이 안 돼서 내가 디자인한 코드를 실행한 걸 볼 수 없다는 게 답답하다', 'tmi자꾸 옆조분이 괴롭힌다 내가 듣는 노래나 가수도 놀리고 이게 노래냐며 듣지말라고 한다 그러면서 이어폰 한 쪽을 달라고 한다', '오늘 팀원들의 기능들을 통합하였다 동건이의 도움으로 달력에 텍스트를 추가하는 기능을 구현했다 하지만 텍스트를 여러개 넣고 싶은데 하나 밖에 추가 되지 않는다 선생님께 조언을 구했더니 코드를 보시고는 텍스트 추가 기능을 넣으면 텍스트 수정 기능이 사라질 것이라고 했다 그래서 추가 기능을 보류하기로 하고 달력에 입력한 메모 텍스트를 firebase와 연동하는 것에 매진하였다 창훈님의 도움으로 firebase에 데이터가 축적되는 것을 구현하였다 앱의 모든 기능들이 구현되는 것을 보고 싶다', '하나씩 하나씩 만들어진게 합쳐져서 완성되는 것이 나름 즐거웠다 힘든 부분도 있었지만 뿌듯한 부분도 있어서 내심 기분이 좋다 오늘은 푹 잘수 있을 것 같다', '병원에 가느라 하루 반을 빠지니 팀에게 너무 미안했다 혹시나 내가 맡은 부분을 못해서 늦어지거나 안될까봐 압박감과 스트레스를 받았다 나 하나로 팀 프로젝트가 잘못되면 안되므로 내가 맡은 부분을 시간내에 완수해야 하는 책임감이 크다', '머리너무아픔 집에가고싶', '앱 디자인과 컬러를 정하는 일은 너무 어렵다 유동적인 부분 고정적인 부분 등 고려해야 할 것도 많다 색상 선정 과정에서도 의견이 분분했다 주관적이었지만 배색 또는 보색 사용에 대해 고민할 수 있었다', '집가고싶다', '실질적으로 프로젝트가 끝났다 GPS랑 출퇴근 버튼이 연동은 안 될 것 같은데 그 부분은 아쉽지만 그래도 이번 기회를 통해 firebase 사용법에 대해서도 잘 익혔고 달력구현도 뭐 완벽히 하는 건 실패했지만 연습해볼 기회가 되었던 것 같다', '즐거웠당 각자 강점을 가진 영역을 살려서 무언가 만들어 내는 과정이 뿌듯하다', '어제부터 해결하지 못한 문제가 오늘 해결되었지만 내가 직접적으로 해결하지 못한게 억울한거 같다', '오늘 뭔가 막막했는데 갑자기 전체적으로 팀 진도가 훅 나가서 뭔가 마음이 굉장히 편해졌다 생각한것도 구현이 잘 되었고 나머지 코드만 잘 취합되면 괜찮게 마무리 할 수 있을 것 같다', '어제 이후 잠은 푹 잤던 것 같고 지금의 팀플이 얼른 끝나고 초기화된 상태에서 다음 과정에서 더 파이팅하고싶다', '처음 경험한 팀플 과정은 흥미로웠으나 어려운 포인트들이 생각보다 많았던 것 같다', '생각보다 잘 풀리는 것 같다 휴식 등으로 재충전을 하고 와서인지 잘 풀렸다', '개발 진행 과정에서 나머지 1부분만 해결하면 된다 나이스  이것도 해결완료', '하나하나씩 문제해결 하다보면 욕심도 비례해 올라가더라 나중에 시간이 허락한다면 팀 프로젝트 때 만든 앱을 분석해보고 싶다', 'firebase 활용이 어렵다', '사실 제대로 익히면 room보다 훨씬 간단하고 활용도도 높은 것 같은데 이번 기회에 잘 익혀야겠다', '새로운 라이브러리나 툴을 다룰 때는 항상 장님이 코끼리 만지듯 하게 되는 것 같다 경험을 통해 배우는 것과 미리 모든 것을 알아두는 것의 차이는 뭘까', 'datepicker 구현을 위해 코드 검색 및 검증하는 작업 과정 중에 bard gpt 가이드가 사실과 많이 다르다  변별이 쉽지 않다', '데이터 디자인 프론트 백 다양하게 하는 경험 즐겁고 좋은 경험이었음', '힘들고 지치고 머리도 띵하지만 즐거운 경험이라고 생각', '새로운 경험 새로운 방법들을 통해서 재밌음', '파이어베이스 부터 다양한 경험을 느낄 수 있었음', '공지사항을 만들려고 하는데 난이도는 그리 높진 않아도 시간이 좀 많이 걸리고 있다 간단하게 만드는 걸 생각해 봐야겠다', '계속 어려운 부분을 도전해야해서 매일 힘들긴 하지만 하고 잘 실행되면 뿌듯해져서 기분이 좋다 계속 도전을 해야겠다', '프로젝트 진전이 있는 것 같지만 팀원들과의 협업과 병합 후 완성될 순간이 아득한데 벌써 코딩할 시간은 하루 남았습니다  잘 완성될지 걱정 반완성 될 프로젝트에 대한 기대반입니다', '파이어베이스 리얼타임을 사용하여 데이터가 연동되는 것을 확인했지만 다른 프로젝트에서 작업하고 있어서 오류가 났다 코드를 다 합쳐서 이제 merge를 하고 네비게이션을 쓴 다음 파이어베이스 연동만 하면 된다 오늘 안에는 끝날 수 있을 것 같기도 한데 다 끝났으면 좋겠다 디자인이나 다른 추가기능을 돕고 싶다', '팀의 열정적인 분위기를 이끌기 위해 주말에도 닦달하는 박누리 차장님의 모습을 보고 좋은 소기업에 입사한 기분이 든다', '나중에 좋은 소기업에 들어가면 바로 도망치거나 퇴직연금까지만 받고 도망치도록 하자', '너무 어려운 것을 선택한 느낌이 들었다 고려해야 할 것도 많고 기능 자체도 어려워서 고민을 많이 하고 있는데 머리가 터질 것 같다 하면 할 수록 머리가 비워지는 느낌이라서 힘들다', '하고싶은건 많지만 시간을 잘 활용하지 못해 많은걸 포기해야 한다  코드 병합과정이 어렵다  디자인은 더어렵다', 'firebase storage에 사진은 올렸는데 가져오진 못함 채팅방에 연동하고싶음', '사진뿐만 아니라 모든 파일을 올리고 싶음', '빨리 할수있는 걸 최대한 빨리 하고 계획도 그때그때 변화시켜서 적용을 하는게 중요한것 같다', '저번 주에 작업을 많이 못해서 어제 최대한 했고 오늘은 생각보다 데이터베이스 auth 가져오는 작업에서 많이 시간이 걸렸다 깃 작업하는데 너무 꼬인다 뭔가 내가 내 깃 작업을 하는 건 잘 진행되는데 팀원 분들 깃 작업하는데 계속 꼬여서 알던 것도 헷갈린다', '팀원들이랑 처음 시작할 때 정확한 기능 구현을 우선 순위로 두고 시작했는데 아직 나는 부족한 것 같다 그렇지만 우리 팀원들 모두가 열심히 참여해줘서 이 정도까지 왔다고 생각한다 12일 정도 남았는데 끝까지 힘내서 해야지', '팀원들의 코드는 거의 다 완성이 되서 Merging을 한다고 하는데 난 지금 아직도 절반밖에 못왔다 진짜 어떻게 하지', '오늘 하루 종일 기능 구현을 하려고 했으나 너무 어려웠다', '아직도 다 구현하지 못했다 챗지피티의 도움을 받고 있는데 어렵다', '혼자 할떄보다 확실히 팀원들과 조언과 도움을 받아서 하니확실히 잘되는부분이 있어 좋다', '계획을 더 상세히 짜서 시간 분배를 잘할 걸 그랬다 시간내에 모든 작업을 다 병합해서 진행할 수 있을지 의문이다', '애초에 qr 스캔까지는 어떻게든 도달한다하더라도', '생성부터 근태 관리를 위한 FireStore 데이터 저장 및 교환은 많이 어려운 영역인 것 같다', '어제 밤샌 작업으로 피곤한 상태인데 최대한 개발 집중하려고 노력했고 결과는 얻은 게 없긴하다', '깃허브 협업이야말로 정말 어려운 것이었다', '깃허브 팀프로젝트 하나로 합치는 머지를 앞두고 있는데 뭐지 싶고 중요한 작업이 맞다', '대략 아는 정도이니 뺄거 빼고 코드 취합할 때 너무 어렵다 알것같은데 막상 건들면 빌드에러파티', '피곤하다', '제로콜라먹고싶음', '오늘 구내식당에서 점심을 먹고 팀원분들과 다른 팀분들과 승강기를 타고 내려갔다', '승강기에서 다른 팀분의 옆모습이 우연히 눈에 들어왔는데 배가 볼록 나오셨다 나도 모르게 웃음을 터뜨렸다 웃음을 참으려고 입술을 앙 물었는데 결국 푸흐흐 하며 웃어버렸다 그분이 왜 저보고 웃어요 담당일진이라니깐 하고 바로 귀신처럼 자기 보고 웃는 걸 알아채셨다 아 나는 왜 웃음을 잘 못 참는거지', 'TMI 프로젝트 작업을 하다 잠깐 강의실 밖으로 나왔는데 다른 분들 방해되지 않도록 천천히 살금살금 문고리를 잡고 나갔다 쾅 소리가 나지 않도록 문이 완전히 닫힐 때까지 문고리를 손에 놓지 않았다  그런데 강의실 안에서 누군가 문고리를 잡고 밀고있었다 나는 그 분이 문고리를 잡고 밀고있든 상관하지 않고 계속 문고리를 밖에서 놓지 않아서 그 분이 밖으로 못 나오셨다 죄송합니다', '아직 병합은 시작도 안했는데 벌써 걱정이 된다', '내가 하고싶은 기능을 추가하기보다 이미 기능은 팀원들 개개인이 많이 진행하고 있어서 db관리하면서 총괄 역할을 했는데 팀원 코드를 합치고 리뷰하는 과정에 에너지를 많이 소모하고 있고 db는 모든 기능 구현에서 써야하기 때문에 어떻게 다른 팀원의 코드에 적용해야할지 고민 하고 있다 다들 너무 잘해주고 있어서 내 파트를 얼른 마무리해야겠다', '아 git 사용 너무 어렵다 공부해야지', '생각한 작업이 구현 되려고 하는데 잘못된 방법으로 접근해서 생각보다 시간을 많이 날려먹었다 이고통이 빨리 끝나길 ', '계속 무한 루프에 걸려서 힘들었다 아 언제 다 해결해내지', '캘린더에 텍스트를 입력하는 것을 구현했는데 이를 Room 예약과 어떻게 연결 지을 지 구상이 떠오르지 않는다 고민은 계속하는데 아무런 결과가 나오지 않으니 팀원들에게 도움이 되지 못하는 것 같아 죄책감이 든다 집에 가서 조금만 더 고민해봐야 겠다', '전략을 바꿔야겠다 UI를 먼저 구성하고 ViewModel을 활용해서 빌드 확인하면서 진행해야겠다 일단은 핵심 기능을 먼저 구현해야겠다 DB랑 디자인은 기능 후에 할 예정이다 뷰모델을 개인 프젝 때 했었는데 팀 프젝 때 또 활용할 지 몰랐다 했는데도 여전히 버벅대고 있다 분명 컨디션은 좋은데 입맛이 없고 액체 말고는 먹고 싶지가 않다 그래도 팀원분들이 파이팅 해주셔서 좋다 청안식탁 닭개장 맛있으니 추천합니다 형준님 음료 쏘신거 매우 감사 열심히 해야지', '달력 구현 어려울 것 알고는 있었지만 역시 어려웠다 그래도 목표했던 부분까지는 해내서 다행이다 시간이 조금 더 있었으면 좋겠다 주말에 시간이 거의 안 날 것 같아서 걱정이다 그래도 하나하나 해결될 때 행복했다 확실히 프로젝트를 연달아 하니까 단기간에 빠르게 성장하는 것 같다 하지만 여전히 많이 부족하다 기본적인 메서드 문법을 자꾸 까먹는다', '주말 어떡해 나 주말에 시간 없는데 아와아와와아아오앙', '초기에는 좌절과 혼란을 느꼈지만 조금씩 이해하면서 진전되는 것에 뿌듯함을 느꼈다 동료들과의 협업이 중요하며 어려움을 겪을 때에도 의지를 갖는 것이 중요하다고 느꼈다', '어제 새벽까지 결과물이 하나도 없어서 힘들었다 코드를 하나씩 분석해서 gpt 없이 내가 해결해야할줄 알아야 할것같다 gpt는 바보니까', '오늘 QR 스캔 관련해서 빌드그래들 추가할게 많고 넣다가 꼬여서 실패 무한루프로 큰 소득은 없었다', '최대한 열심히 하였다 gradle 버전과 코틀린 버전이 안맞아서 엄청 고생했지만 도움을 받아 해결할 수 있었다', '진도가 빨리 안 나가서 불안한 느낌이 든다 최대한 디자인보다는 기능을 구현하려고 하는데 배운 내용이 잘 기억이 안 나고 특히 데이터 연동 부분이 어렵다 되는 대로 하고 있지만 최대한 팀원들에게 물어보며 해야겠다', '이번에 firebase를 쓰는데 room쓰는 것 보다 더 복잡하고 어려워서 공부를 많이 해야할 것 같다 그래도 일단 틀은 다 짜서 다행이다', '디자인이 역시 재밌다', '빨리 메신저 기능 구현하고 싶다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feeling_tokenizer = Tokenizer()\n",
        "feeling_tokenizer.fit_on_texts(cleaned_feeling)\n",
        "feeling_vocab_size = len(feeling_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "0t7QscOqnrnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lesson_tokenizer = Tokenizer()\n",
        "lesson_tokenizer.fit_on_texts(cleaned_lesson)\n",
        "lesson_vocab_size = len(lesson_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "KYBWInmNy70s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_feeling = list()\n",
        "\n",
        "for line in cleaned_feeling:\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0] # 각  샘플에  대한  정수  인코딩\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences_feeling.append(sequence)"
      ],
      "metadata": {
        "id": "k5FoZGnZtcbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_lesson = list()\n",
        "\n",
        "for line in cleaned_lesson:\n",
        "    encoded = lesson_tokenizer.texts_to_sequences([line])[0] # 각  샘플에  대한  정수  인코딩\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences_lesson.append(sequence)"
      ],
      "metadata": {
        "id": "W2Mqn9wqzJNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_feeling[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CQxT-JKmixb",
        "outputId": "f068eb06-77ac-438d-a947-e0115838d196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 134], [6, 193], [6, 193, 3], [6, 193, 3, 580], [6, 193, 3, 580, 101]]"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feeling_max_len=max(len(l) for l in sequences_feeling) # 가장  긴  샘플의  길이  확인\n",
        "print('샘플의  최대  길이  : {}'.format(feeling_max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-F9pJKYtJ61",
        "outputId": "7b43f225-a3bc-4983-a38c-365b6bc55b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의  최대  길이  : 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lesson_max_len=max(len(l) for l in sequences_lesson) # 가장  긴  샘플의  길이  확인\n",
        "print('샘플의  최대  길이  : {}'.format(lesson_max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESEaIkOIzT8R",
        "outputId": "458fefa9-d758-448d-908e-83f07da4544b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의  최대  길이  : 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_feeling = pad_sequences(sequences_feeling,maxlen=feeling_max_len, padding = 'pre')\n",
        "train_X_feeling = sequences_feeling[:,:-1]\n",
        "train_y_feeling = sequences_feeling[:,-1]"
      ],
      "metadata": {
        "id": "z6RtoGJUtKzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_feeling = to_categorical(train_y_feeling, num_classes=feeling_vocab_size)\n",
        "train_y_feeling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQm8RzHcqbc1",
        "outputId": "8766e0b8-1ae2-4ed7-9283-0ee609871cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_lesson = pad_sequences(sequences_lesson,maxlen=lesson_max_len, padding = 'pre')\n",
        "train_X_lesson = sequences_lesson[:,:-1]\n",
        "train_y_lesson = sequences_lesson[:,-1]"
      ],
      "metadata": {
        "id": "fBHIFOYargRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_lesson = to_categorical(train_y_lesson, num_classes=lesson_vocab_size)\n",
        "train_y_lesson"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtnYfn0YzkiK",
        "outputId": "1011037d-e9f8-4079-b086-83afea3d8094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feeling_model = Sequential()\n",
        "# y데이터를  분리하였으므로  이제  X데이터의  길이는  기존  데이터의  길이  - 1\n",
        "feeling_model.add(Embedding(feeling_vocab_size, 10, input_length=feeling_max_len-1)) # 10: 계산된 결과를 몇개까지 만들것인다\n",
        "feeling_model.add(LSTM(128))\n",
        "feeling_model.add(Dense(feeling_vocab_size, activation='softmax'))\n",
        "feeling_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "feeling_model.fit(train_X_feeling, train_y_feeling, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpG8_pQUq4c4",
        "outputId": "cbf01666-d521-4903-d676-508d89175139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "134/134 - 12s - loss: 7.8727 - accuracy: 0.0124 - 12s/epoch - 88ms/step\n",
            "Epoch 2/100\n",
            "134/134 - 9s - loss: 7.6622 - accuracy: 0.0126 - 9s/epoch - 70ms/step\n",
            "Epoch 3/100\n",
            "134/134 - 8s - loss: 7.4953 - accuracy: 0.0135 - 8s/epoch - 59ms/step\n",
            "Epoch 4/100\n",
            "134/134 - 9s - loss: 7.4479 - accuracy: 0.0117 - 9s/epoch - 64ms/step\n",
            "Epoch 5/100\n",
            "134/134 - 9s - loss: 7.3283 - accuracy: 0.0131 - 9s/epoch - 64ms/step\n",
            "Epoch 6/100\n",
            "134/134 - 8s - loss: 7.1993 - accuracy: 0.0152 - 8s/epoch - 58ms/step\n",
            "Epoch 7/100\n",
            "134/134 - 9s - loss: 7.0073 - accuracy: 0.0170 - 9s/epoch - 64ms/step\n",
            "Epoch 8/100\n",
            "134/134 - 9s - loss: 6.7502 - accuracy: 0.0187 - 9s/epoch - 64ms/step\n",
            "Epoch 9/100\n",
            "134/134 - 8s - loss: 6.4580 - accuracy: 0.0243 - 8s/epoch - 63ms/step\n",
            "Epoch 10/100\n",
            "134/134 - 8s - loss: 6.1562 - accuracy: 0.0254 - 8s/epoch - 60ms/step\n",
            "Epoch 11/100\n",
            "134/134 - 9s - loss: 5.8429 - accuracy: 0.0306 - 9s/epoch - 64ms/step\n",
            "Epoch 12/100\n",
            "134/134 - 9s - loss: 5.5477 - accuracy: 0.0394 - 9s/epoch - 65ms/step\n",
            "Epoch 13/100\n",
            "134/134 - 8s - loss: 5.2623 - accuracy: 0.0537 - 8s/epoch - 57ms/step\n",
            "Epoch 14/100\n",
            "134/134 - 9s - loss: 4.9952 - accuracy: 0.0700 - 9s/epoch - 63ms/step\n",
            "Epoch 15/100\n",
            "134/134 - 8s - loss: 4.7415 - accuracy: 0.0898 - 8s/epoch - 63ms/step\n",
            "Epoch 16/100\n",
            "134/134 - 8s - loss: 4.4920 - accuracy: 0.1286 - 8s/epoch - 60ms/step\n",
            "Epoch 17/100\n",
            "134/134 - 8s - loss: 4.2647 - accuracy: 0.1722 - 8s/epoch - 61ms/step\n",
            "Epoch 18/100\n",
            "134/134 - 9s - loss: 4.0541 - accuracy: 0.2224 - 9s/epoch - 64ms/step\n",
            "Epoch 19/100\n",
            "134/134 - 8s - loss: 3.8377 - accuracy: 0.2660 - 8s/epoch - 63ms/step\n",
            "Epoch 20/100\n",
            "134/134 - 8s - loss: 3.6370 - accuracy: 0.3094 - 8s/epoch - 58ms/step\n",
            "Epoch 21/100\n",
            "134/134 - 10s - loss: 3.4484 - accuracy: 0.3565 - 10s/epoch - 75ms/step\n",
            "Epoch 22/100\n",
            "134/134 - 9s - loss: 3.2666 - accuracy: 0.3994 - 9s/epoch - 66ms/step\n",
            "Epoch 23/100\n",
            "134/134 - 8s - loss: 3.1041 - accuracy: 0.4398 - 8s/epoch - 63ms/step\n",
            "Epoch 24/100\n",
            "134/134 - 8s - loss: 2.9316 - accuracy: 0.4711 - 8s/epoch - 58ms/step\n",
            "Epoch 25/100\n",
            "134/134 - 9s - loss: 2.7829 - accuracy: 0.5128 - 9s/epoch - 63ms/step\n",
            "Epoch 26/100\n",
            "134/134 - 9s - loss: 2.6337 - accuracy: 0.5292 - 9s/epoch - 64ms/step\n",
            "Epoch 27/100\n",
            "134/134 - 8s - loss: 2.4944 - accuracy: 0.5740 - 8s/epoch - 59ms/step\n",
            "Epoch 28/100\n",
            "134/134 - 9s - loss: 2.3676 - accuracy: 0.5910 - 9s/epoch - 64ms/step\n",
            "Epoch 29/100\n",
            "134/134 - 9s - loss: 2.2412 - accuracy: 0.6234 - 9s/epoch - 63ms/step\n",
            "Epoch 30/100\n",
            "134/134 - 8s - loss: 2.1302 - accuracy: 0.6484 - 8s/epoch - 62ms/step\n",
            "Epoch 31/100\n",
            "134/134 - 8s - loss: 2.0191 - accuracy: 0.6687 - 8s/epoch - 59ms/step\n",
            "Epoch 32/100\n",
            "134/134 - 8s - loss: 1.9208 - accuracy: 0.6881 - 8s/epoch - 63ms/step\n",
            "Epoch 33/100\n",
            "134/134 - 8s - loss: 1.8423 - accuracy: 0.7030 - 8s/epoch - 63ms/step\n",
            "Epoch 34/100\n",
            "134/134 - 8s - loss: 1.7325 - accuracy: 0.7296 - 8s/epoch - 63ms/step\n",
            "Epoch 35/100\n",
            "134/134 - 9s - loss: 1.6430 - accuracy: 0.7401 - 9s/epoch - 64ms/step\n",
            "Epoch 36/100\n",
            "134/134 - 9s - loss: 1.5651 - accuracy: 0.7527 - 9s/epoch - 63ms/step\n",
            "Epoch 37/100\n",
            "134/134 - 8s - loss: 1.4864 - accuracy: 0.7671 - 8s/epoch - 62ms/step\n",
            "Epoch 38/100\n",
            "134/134 - 8s - loss: 1.4170 - accuracy: 0.7800 - 8s/epoch - 59ms/step\n",
            "Epoch 39/100\n",
            "134/134 - 9s - loss: 1.3566 - accuracy: 0.7893 - 9s/epoch - 64ms/step\n",
            "Epoch 40/100\n",
            "134/134 - 8s - loss: 1.2840 - accuracy: 0.8052 - 8s/epoch - 63ms/step\n",
            "Epoch 41/100\n",
            "134/134 - 8s - loss: 1.2318 - accuracy: 0.8115 - 8s/epoch - 58ms/step\n",
            "Epoch 42/100\n",
            "134/134 - 8s - loss: 1.1672 - accuracy: 0.8231 - 8s/epoch - 63ms/step\n",
            "Epoch 43/100\n",
            "134/134 - 9s - loss: 1.1122 - accuracy: 0.8339 - 9s/epoch - 64ms/step\n",
            "Epoch 44/100\n",
            "134/134 - 8s - loss: 1.0639 - accuracy: 0.8374 - 8s/epoch - 57ms/step\n",
            "Epoch 45/100\n",
            "134/134 - 9s - loss: 1.0159 - accuracy: 0.8504 - 9s/epoch - 64ms/step\n",
            "Epoch 46/100\n",
            "134/134 - 9s - loss: 0.9698 - accuracy: 0.8549 - 9s/epoch - 64ms/step\n",
            "Epoch 47/100\n",
            "134/134 - 8s - loss: 0.9289 - accuracy: 0.8626 - 8s/epoch - 63ms/step\n",
            "Epoch 48/100\n",
            "134/134 - 8s - loss: 0.8829 - accuracy: 0.8689 - 8s/epoch - 58ms/step\n",
            "Epoch 49/100\n",
            "134/134 - 9s - loss: 0.8458 - accuracy: 0.8749 - 9s/epoch - 64ms/step\n",
            "Epoch 50/100\n",
            "134/134 - 9s - loss: 0.8103 - accuracy: 0.8782 - 9s/epoch - 64ms/step\n",
            "Epoch 51/100\n",
            "134/134 - 8s - loss: 0.7744 - accuracy: 0.8822 - 8s/epoch - 58ms/step\n",
            "Epoch 52/100\n",
            "134/134 - 8s - loss: 0.7391 - accuracy: 0.8882 - 8s/epoch - 63ms/step\n",
            "Epoch 53/100\n",
            "134/134 - 8s - loss: 0.7129 - accuracy: 0.8973 - 8s/epoch - 63ms/step\n",
            "Epoch 54/100\n",
            "134/134 - 8s - loss: 0.6812 - accuracy: 0.9006 - 8s/epoch - 59ms/step\n",
            "Epoch 55/100\n",
            "134/134 - 8s - loss: 0.6527 - accuracy: 0.9032 - 8s/epoch - 63ms/step\n",
            "Epoch 56/100\n",
            "134/134 - 8s - loss: 0.6300 - accuracy: 0.9034 - 8s/epoch - 63ms/step\n",
            "Epoch 57/100\n",
            "134/134 - 9s - loss: 0.6008 - accuracy: 0.9088 - 9s/epoch - 63ms/step\n",
            "Epoch 58/100\n",
            "134/134 - 8s - loss: 0.5751 - accuracy: 0.9123 - 8s/epoch - 58ms/step\n",
            "Epoch 59/100\n",
            "134/134 - 9s - loss: 0.5535 - accuracy: 0.9120 - 9s/epoch - 64ms/step\n",
            "Epoch 60/100\n",
            "134/134 - 9s - loss: 0.5317 - accuracy: 0.9165 - 9s/epoch - 64ms/step\n",
            "Epoch 61/100\n",
            "134/134 - 8s - loss: 0.5173 - accuracy: 0.9207 - 8s/epoch - 58ms/step\n",
            "Epoch 62/100\n",
            "134/134 - 9s - loss: 0.4926 - accuracy: 0.9251 - 9s/epoch - 63ms/step\n",
            "Epoch 63/100\n",
            "134/134 - 9s - loss: 0.4731 - accuracy: 0.9232 - 9s/epoch - 63ms/step\n",
            "Epoch 64/100\n",
            "134/134 - 8s - loss: 0.4552 - accuracy: 0.9265 - 8s/epoch - 61ms/step\n",
            "Epoch 65/100\n",
            "134/134 - 8s - loss: 0.4396 - accuracy: 0.9291 - 8s/epoch - 60ms/step\n",
            "Epoch 66/100\n",
            "134/134 - 9s - loss: 0.4568 - accuracy: 0.9249 - 9s/epoch - 64ms/step\n",
            "Epoch 67/100\n",
            "134/134 - 8s - loss: 1.1498 - accuracy: 0.7865 - 8s/epoch - 63ms/step\n",
            "Epoch 68/100\n",
            "134/134 - 8s - loss: 0.5868 - accuracy: 0.9116 - 8s/epoch - 63ms/step\n",
            "Epoch 69/100\n",
            "134/134 - 8s - loss: 0.4385 - accuracy: 0.9314 - 8s/epoch - 63ms/step\n",
            "Epoch 70/100\n",
            "134/134 - 8s - loss: 0.4001 - accuracy: 0.9361 - 8s/epoch - 63ms/step\n",
            "Epoch 71/100\n",
            "134/134 - 8s - loss: 0.3786 - accuracy: 0.9386 - 8s/epoch - 61ms/step\n",
            "Epoch 72/100\n",
            "134/134 - 8s - loss: 0.3619 - accuracy: 0.9403 - 8s/epoch - 61ms/step\n",
            "Epoch 73/100\n",
            "134/134 - 9s - loss: 0.3479 - accuracy: 0.9426 - 9s/epoch - 63ms/step\n",
            "Epoch 74/100\n",
            "134/134 - 8s - loss: 0.3356 - accuracy: 0.9424 - 8s/epoch - 63ms/step\n",
            "Epoch 75/100\n",
            "134/134 - 8s - loss: 0.3251 - accuracy: 0.9445 - 8s/epoch - 58ms/step\n",
            "Epoch 76/100\n",
            "134/134 - 9s - loss: 0.3152 - accuracy: 0.9463 - 9s/epoch - 64ms/step\n",
            "Epoch 77/100\n",
            "134/134 - 9s - loss: 0.3059 - accuracy: 0.9456 - 9s/epoch - 64ms/step\n",
            "Epoch 78/100\n",
            "134/134 - 8s - loss: 0.2971 - accuracy: 0.9477 - 8s/epoch - 58ms/step\n",
            "Epoch 79/100\n",
            "134/134 - 9s - loss: 0.2882 - accuracy: 0.9489 - 9s/epoch - 64ms/step\n",
            "Epoch 80/100\n",
            "134/134 - 8s - loss: 0.2796 - accuracy: 0.9517 - 8s/epoch - 63ms/step\n",
            "Epoch 81/100\n",
            "134/134 - 8s - loss: 0.2711 - accuracy: 0.9519 - 8s/epoch - 63ms/step\n",
            "Epoch 82/100\n",
            "134/134 - 8s - loss: 0.2635 - accuracy: 0.9526 - 8s/epoch - 58ms/step\n",
            "Epoch 83/100\n",
            "134/134 - 9s - loss: 0.2575 - accuracy: 0.9540 - 9s/epoch - 64ms/step\n",
            "Epoch 84/100\n",
            "134/134 - 8s - loss: 0.2498 - accuracy: 0.9550 - 8s/epoch - 63ms/step\n",
            "Epoch 85/100\n",
            "134/134 - 8s - loss: 0.2428 - accuracy: 0.9559 - 8s/epoch - 58ms/step\n",
            "Epoch 86/100\n",
            "134/134 - 9s - loss: 0.2354 - accuracy: 0.9566 - 9s/epoch - 64ms/step\n",
            "Epoch 87/100\n",
            "134/134 - 9s - loss: 0.2280 - accuracy: 0.9608 - 9s/epoch - 64ms/step\n",
            "Epoch 88/100\n",
            "134/134 - 8s - loss: 0.2212 - accuracy: 0.9578 - 8s/epoch - 59ms/step\n",
            "Epoch 89/100\n",
            "134/134 - 8s - loss: 0.2145 - accuracy: 0.9594 - 8s/epoch - 62ms/step\n",
            "Epoch 90/100\n",
            "134/134 - 9s - loss: 0.2099 - accuracy: 0.9606 - 9s/epoch - 64ms/step\n",
            "Epoch 91/100\n",
            "134/134 - 9s - loss: 0.2051 - accuracy: 0.9613 - 9s/epoch - 64ms/step\n",
            "Epoch 92/100\n",
            "134/134 - 8s - loss: 0.1996 - accuracy: 0.9617 - 8s/epoch - 58ms/step\n",
            "Epoch 93/100\n",
            "134/134 - 9s - loss: 0.1919 - accuracy: 0.9622 - 9s/epoch - 63ms/step\n",
            "Epoch 94/100\n",
            "134/134 - 9s - loss: 0.1845 - accuracy: 0.9643 - 9s/epoch - 64ms/step\n",
            "Epoch 95/100\n",
            "134/134 - 8s - loss: 0.1794 - accuracy: 0.9671 - 8s/epoch - 57ms/step\n",
            "Epoch 96/100\n",
            "134/134 - 8s - loss: 0.1741 - accuracy: 0.9683 - 8s/epoch - 63ms/step\n",
            "Epoch 97/100\n",
            "134/134 - 9s - loss: 0.1689 - accuracy: 0.9669 - 9s/epoch - 64ms/step\n",
            "Epoch 98/100\n",
            "134/134 - 8s - loss: 0.1629 - accuracy: 0.9678 - 8s/epoch - 61ms/step\n",
            "Epoch 99/100\n",
            "134/134 - 8s - loss: 0.1581 - accuracy: 0.9680 - 8s/epoch - 59ms/step\n",
            "Epoch 100/100\n",
            "134/134 - 8s - loss: 0.1532 - accuracy: 0.9701 - 8s/epoch - 63ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ddaa1d9ccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lesson_model = Sequential()\n",
        "# y데이터를  분리하였으므로  이제  X데이터의  길이는  기존  데이터의  길이  - 1\n",
        "lesson_model.add(Embedding(lesson_vocab_size, 10, input_length=lesson_max_len-1)) # 10: 계산된 결과를 몇개까지 만들것인다\n",
        "lesson_model.add(LSTM(128))\n",
        "lesson_model.add(Dense(lesson_vocab_size, activation='softmax'))\n",
        "lesson_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "lesson_model.fit(train_X_lesson, train_y_lesson, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-DgDJJzxsP",
        "outputId": "c113e279-62a7-4d84-c2c4-10b382eb4f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "48/48 - 4s - loss: 7.1224 - accuracy: 0.0099 - 4s/epoch - 78ms/step\n",
            "Epoch 2/100\n",
            "48/48 - 2s - loss: 7.0518 - accuracy: 0.0113 - 2s/epoch - 38ms/step\n",
            "Epoch 3/100\n",
            "48/48 - 3s - loss: 6.9678 - accuracy: 0.0079 - 3s/epoch - 55ms/step\n",
            "Epoch 4/100\n",
            "48/48 - 2s - loss: 6.8817 - accuracy: 0.0099 - 2s/epoch - 38ms/step\n",
            "Epoch 5/100\n",
            "48/48 - 2s - loss: 6.8361 - accuracy: 0.0139 - 2s/epoch - 38ms/step\n",
            "Epoch 6/100\n",
            "48/48 - 2s - loss: 6.7773 - accuracy: 0.0146 - 2s/epoch - 38ms/step\n",
            "Epoch 7/100\n",
            "48/48 - 2s - loss: 6.6690 - accuracy: 0.0132 - 2s/epoch - 38ms/step\n",
            "Epoch 8/100\n",
            "48/48 - 2s - loss: 6.5874 - accuracy: 0.0159 - 2s/epoch - 50ms/step\n",
            "Epoch 9/100\n",
            "48/48 - 3s - loss: 6.4286 - accuracy: 0.0132 - 3s/epoch - 61ms/step\n",
            "Epoch 10/100\n",
            "48/48 - 2s - loss: 6.2812 - accuracy: 0.0159 - 2s/epoch - 39ms/step\n",
            "Epoch 11/100\n",
            "48/48 - 2s - loss: 6.1233 - accuracy: 0.0165 - 2s/epoch - 38ms/step\n",
            "Epoch 12/100\n",
            "48/48 - 2s - loss: 5.9644 - accuracy: 0.0232 - 2s/epoch - 38ms/step\n",
            "Epoch 13/100\n",
            "48/48 - 2s - loss: 5.8148 - accuracy: 0.0251 - 2s/epoch - 37ms/step\n",
            "Epoch 14/100\n",
            "48/48 - 2s - loss: 5.6476 - accuracy: 0.0318 - 2s/epoch - 38ms/step\n",
            "Epoch 15/100\n",
            "48/48 - 3s - loss: 5.4741 - accuracy: 0.0351 - 3s/epoch - 55ms/step\n",
            "Epoch 16/100\n",
            "48/48 - 2s - loss: 5.2992 - accuracy: 0.0424 - 2s/epoch - 40ms/step\n",
            "Epoch 17/100\n",
            "48/48 - 2s - loss: 5.1444 - accuracy: 0.0450 - 2s/epoch - 38ms/step\n",
            "Epoch 18/100\n",
            "48/48 - 2s - loss: 4.9783 - accuracy: 0.0549 - 2s/epoch - 37ms/step\n",
            "Epoch 19/100\n",
            "48/48 - 2s - loss: 4.7975 - accuracy: 0.0642 - 2s/epoch - 37ms/step\n",
            "Epoch 20/100\n",
            "48/48 - 2s - loss: 4.6428 - accuracy: 0.0847 - 2s/epoch - 39ms/step\n",
            "Epoch 21/100\n",
            "48/48 - 3s - loss: 4.4920 - accuracy: 0.0874 - 3s/epoch - 52ms/step\n",
            "Epoch 22/100\n",
            "48/48 - 2s - loss: 4.3469 - accuracy: 0.0999 - 2s/epoch - 39ms/step\n",
            "Epoch 23/100\n",
            "48/48 - 2s - loss: 4.1909 - accuracy: 0.1277 - 2s/epoch - 39ms/step\n",
            "Epoch 24/100\n",
            "48/48 - 2s - loss: 4.0560 - accuracy: 0.1549 - 2s/epoch - 38ms/step\n",
            "Epoch 25/100\n",
            "48/48 - 2s - loss: 3.9187 - accuracy: 0.1820 - 2s/epoch - 38ms/step\n",
            "Epoch 26/100\n",
            "48/48 - 2s - loss: 3.7757 - accuracy: 0.2277 - 2s/epoch - 39ms/step\n",
            "Epoch 27/100\n",
            "48/48 - 3s - loss: 3.6594 - accuracy: 0.2528 - 3s/epoch - 54ms/step\n",
            "Epoch 28/100\n",
            "48/48 - 2s - loss: 3.5285 - accuracy: 0.2727 - 2s/epoch - 39ms/step\n",
            "Epoch 29/100\n",
            "48/48 - 2s - loss: 3.4131 - accuracy: 0.2991 - 2s/epoch - 38ms/step\n",
            "Epoch 30/100\n",
            "48/48 - 2s - loss: 3.2954 - accuracy: 0.3455 - 2s/epoch - 38ms/step\n",
            "Epoch 31/100\n",
            "48/48 - 2s - loss: 3.1894 - accuracy: 0.3488 - 2s/epoch - 39ms/step\n",
            "Epoch 32/100\n",
            "48/48 - 2s - loss: 3.0761 - accuracy: 0.3991 - 2s/epoch - 39ms/step\n",
            "Epoch 33/100\n",
            "48/48 - 3s - loss: 2.9729 - accuracy: 0.4229 - 3s/epoch - 55ms/step\n",
            "Epoch 34/100\n",
            "48/48 - 2s - loss: 2.8754 - accuracy: 0.4520 - 2s/epoch - 38ms/step\n",
            "Epoch 35/100\n",
            "48/48 - 2s - loss: 2.7757 - accuracy: 0.4931 - 2s/epoch - 38ms/step\n",
            "Epoch 36/100\n",
            "48/48 - 2s - loss: 2.6798 - accuracy: 0.5103 - 2s/epoch - 38ms/step\n",
            "Epoch 37/100\n",
            "48/48 - 2s - loss: 2.5905 - accuracy: 0.5242 - 2s/epoch - 38ms/step\n",
            "Epoch 38/100\n",
            "48/48 - 2s - loss: 2.5043 - accuracy: 0.5513 - 2s/epoch - 38ms/step\n",
            "Epoch 39/100\n",
            "48/48 - 3s - loss: 2.4124 - accuracy: 0.5831 - 3s/epoch - 54ms/step\n",
            "Epoch 40/100\n",
            "48/48 - 2s - loss: 2.3323 - accuracy: 0.6095 - 2s/epoch - 38ms/step\n",
            "Epoch 41/100\n",
            "48/48 - 2s - loss: 2.2531 - accuracy: 0.6221 - 2s/epoch - 38ms/step\n",
            "Epoch 42/100\n",
            "48/48 - 2s - loss: 2.1797 - accuracy: 0.6519 - 2s/epoch - 39ms/step\n",
            "Epoch 43/100\n",
            "48/48 - 2s - loss: 2.1086 - accuracy: 0.6631 - 2s/epoch - 38ms/step\n",
            "Epoch 44/100\n",
            "48/48 - 2s - loss: 2.0373 - accuracy: 0.6810 - 2s/epoch - 40ms/step\n",
            "Epoch 45/100\n",
            "48/48 - 3s - loss: 1.9719 - accuracy: 0.6942 - 3s/epoch - 53ms/step\n",
            "Epoch 46/100\n",
            "48/48 - 2s - loss: 1.9072 - accuracy: 0.7002 - 2s/epoch - 39ms/step\n",
            "Epoch 47/100\n",
            "48/48 - 2s - loss: 1.8410 - accuracy: 0.7148 - 2s/epoch - 39ms/step\n",
            "Epoch 48/100\n",
            "48/48 - 2s - loss: 1.7788 - accuracy: 0.7353 - 2s/epoch - 38ms/step\n",
            "Epoch 49/100\n",
            "48/48 - 2s - loss: 1.7277 - accuracy: 0.7287 - 2s/epoch - 38ms/step\n",
            "Epoch 50/100\n",
            "48/48 - 2s - loss: 1.6826 - accuracy: 0.7445 - 2s/epoch - 40ms/step\n",
            "Epoch 51/100\n",
            "48/48 - 3s - loss: 1.6172 - accuracy: 0.7538 - 3s/epoch - 53ms/step\n",
            "Epoch 52/100\n",
            "48/48 - 2s - loss: 1.5636 - accuracy: 0.7737 - 2s/epoch - 38ms/step\n",
            "Epoch 53/100\n",
            "48/48 - 2s - loss: 1.5158 - accuracy: 0.7750 - 2s/epoch - 38ms/step\n",
            "Epoch 54/100\n",
            "48/48 - 2s - loss: 1.4688 - accuracy: 0.7948 - 2s/epoch - 38ms/step\n",
            "Epoch 55/100\n",
            "48/48 - 2s - loss: 1.4383 - accuracy: 0.8008 - 2s/epoch - 38ms/step\n",
            "Epoch 56/100\n",
            "48/48 - 2s - loss: 1.3774 - accuracy: 0.8061 - 2s/epoch - 39ms/step\n",
            "Epoch 57/100\n",
            "48/48 - 3s - loss: 1.3924 - accuracy: 0.7988 - 3s/epoch - 52ms/step\n",
            "Epoch 58/100\n",
            "48/48 - 2s - loss: 1.3085 - accuracy: 0.8107 - 2s/epoch - 39ms/step\n",
            "Epoch 59/100\n",
            "48/48 - 2s - loss: 1.2579 - accuracy: 0.8193 - 2s/epoch - 38ms/step\n",
            "Epoch 60/100\n",
            "48/48 - 2s - loss: 1.2162 - accuracy: 0.8286 - 2s/epoch - 39ms/step\n",
            "Epoch 61/100\n",
            "48/48 - 2s - loss: 1.1796 - accuracy: 0.8312 - 2s/epoch - 38ms/step\n",
            "Epoch 62/100\n",
            "48/48 - 2s - loss: 1.1434 - accuracy: 0.8385 - 2s/epoch - 41ms/step\n",
            "Epoch 63/100\n",
            "48/48 - 2s - loss: 1.1134 - accuracy: 0.8412 - 2s/epoch - 52ms/step\n",
            "Epoch 64/100\n",
            "48/48 - 2s - loss: 1.0778 - accuracy: 0.8412 - 2s/epoch - 38ms/step\n",
            "Epoch 65/100\n",
            "48/48 - 2s - loss: 1.0440 - accuracy: 0.8432 - 2s/epoch - 39ms/step\n",
            "Epoch 66/100\n",
            "48/48 - 2s - loss: 1.0144 - accuracy: 0.8623 - 2s/epoch - 39ms/step\n",
            "Epoch 67/100\n",
            "48/48 - 2s - loss: 0.9838 - accuracy: 0.8590 - 2s/epoch - 38ms/step\n",
            "Epoch 68/100\n",
            "48/48 - 2s - loss: 0.9542 - accuracy: 0.8670 - 2s/epoch - 41ms/step\n",
            "Epoch 69/100\n",
            "48/48 - 2s - loss: 0.9243 - accuracy: 0.8650 - 2s/epoch - 52ms/step\n",
            "Epoch 70/100\n",
            "48/48 - 2s - loss: 0.8975 - accuracy: 0.8743 - 2s/epoch - 38ms/step\n",
            "Epoch 71/100\n",
            "48/48 - 2s - loss: 0.8743 - accuracy: 0.8670 - 2s/epoch - 38ms/step\n",
            "Epoch 72/100\n",
            "48/48 - 2s - loss: 0.8459 - accuracy: 0.8743 - 2s/epoch - 38ms/step\n",
            "Epoch 73/100\n",
            "48/48 - 2s - loss: 0.8300 - accuracy: 0.8736 - 2s/epoch - 37ms/step\n",
            "Epoch 74/100\n",
            "48/48 - 2s - loss: 0.8019 - accuracy: 0.8815 - 2s/epoch - 42ms/step\n",
            "Epoch 75/100\n",
            "48/48 - 2s - loss: 0.7781 - accuracy: 0.8815 - 2s/epoch - 50ms/step\n",
            "Epoch 76/100\n",
            "48/48 - 2s - loss: 0.7567 - accuracy: 0.8795 - 2s/epoch - 39ms/step\n",
            "Epoch 77/100\n",
            "48/48 - 2s - loss: 0.7420 - accuracy: 0.8915 - 2s/epoch - 40ms/step\n",
            "Epoch 78/100\n",
            "48/48 - 2s - loss: 0.7174 - accuracy: 0.8934 - 2s/epoch - 38ms/step\n",
            "Epoch 79/100\n",
            "48/48 - 2s - loss: 0.6962 - accuracy: 0.8974 - 2s/epoch - 39ms/step\n",
            "Epoch 80/100\n",
            "48/48 - 2s - loss: 0.6771 - accuracy: 0.9014 - 2s/epoch - 46ms/step\n",
            "Epoch 81/100\n",
            "48/48 - 2s - loss: 0.6595 - accuracy: 0.8941 - 2s/epoch - 47ms/step\n",
            "Epoch 82/100\n",
            "48/48 - 2s - loss: 0.6429 - accuracy: 0.8994 - 2s/epoch - 39ms/step\n",
            "Epoch 83/100\n",
            "48/48 - 2s - loss: 0.6265 - accuracy: 0.8994 - 2s/epoch - 38ms/step\n",
            "Epoch 84/100\n",
            "48/48 - 2s - loss: 0.6085 - accuracy: 0.9067 - 2s/epoch - 38ms/step\n",
            "Epoch 85/100\n",
            "48/48 - 2s - loss: 0.5923 - accuracy: 0.9093 - 2s/epoch - 38ms/step\n",
            "Epoch 86/100\n",
            "48/48 - 2s - loss: 0.5806 - accuracy: 0.9093 - 2s/epoch - 45ms/step\n",
            "Epoch 87/100\n",
            "48/48 - 2s - loss: 0.5621 - accuracy: 0.9080 - 2s/epoch - 47ms/step\n",
            "Epoch 88/100\n",
            "48/48 - 2s - loss: 0.5520 - accuracy: 0.9113 - 2s/epoch - 38ms/step\n",
            "Epoch 89/100\n",
            "48/48 - 2s - loss: 0.5372 - accuracy: 0.9107 - 2s/epoch - 39ms/step\n",
            "Epoch 90/100\n",
            "48/48 - 2s - loss: 0.5239 - accuracy: 0.9153 - 2s/epoch - 38ms/step\n",
            "Epoch 91/100\n",
            "48/48 - 2s - loss: 0.5133 - accuracy: 0.9153 - 2s/epoch - 38ms/step\n",
            "Epoch 92/100\n",
            "48/48 - 2s - loss: 0.4986 - accuracy: 0.9219 - 2s/epoch - 46ms/step\n",
            "Epoch 93/100\n",
            "48/48 - 2s - loss: 0.4870 - accuracy: 0.9193 - 2s/epoch - 47ms/step\n",
            "Epoch 94/100\n",
            "48/48 - 2s - loss: 0.4758 - accuracy: 0.9265 - 2s/epoch - 39ms/step\n",
            "Epoch 95/100\n",
            "48/48 - 2s - loss: 0.4618 - accuracy: 0.9305 - 2s/epoch - 38ms/step\n",
            "Epoch 96/100\n",
            "48/48 - 2s - loss: 0.4508 - accuracy: 0.9232 - 2s/epoch - 38ms/step\n",
            "Epoch 97/100\n",
            "48/48 - 2s - loss: 0.4424 - accuracy: 0.9265 - 2s/epoch - 38ms/step\n",
            "Epoch 98/100\n",
            "48/48 - 2s - loss: 0.4308 - accuracy: 0.9298 - 2s/epoch - 47ms/step\n",
            "Epoch 99/100\n",
            "48/48 - 2s - loss: 0.4192 - accuracy: 0.9312 - 2s/epoch - 46ms/step\n",
            "Epoch 100/100\n",
            "48/48 - 2s - loss: 0.4095 - accuracy: 0.9338 - 2s/epoch - 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ddaa51c4700>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def feeling_generation(model, t, current_word, n): # 모델, 토크나이저, 현재  단어, 반복핛  횟수\n",
        "    init_word = current_word # 처음  들어온  단어도  마지막에  같이  출력하기위해  저장\n",
        "    sentence = ''\n",
        "    for _ in range(n): # n번  반복\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재  단어에  대핚  정수  인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=74, padding='pre') # 데이터에  대한  패딩\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=-1)\n",
        "        for word, index in t.word_index.items():\n",
        "            if index == result: # 맊약  예측핚  단어와  인덱스와  동일한  단어가  있다면\n",
        "                break # 해당  단어가  예측  단어이므로  break\n",
        "        current_word = current_word + ' '  + word # 현재  단어  + ' ' + 예측  단어를  현재  단어로  변경\n",
        "        sentence = sentence + ' ' + word # 예측  단어를  문장에  저장\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return \"느낌 : \" + sentence"
      ],
      "metadata": {
        "id": "yyNljbYwrTb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lesson_generation(model, t, current_word, n): # 모델, 토크나이저, 현재  단어, 반복핛  횟수\n",
        "    init_word = current_word # 처음  들어온  단어도  마지막에  같이  출력하기위해  저장\n",
        "    sentence = ''\n",
        "    for _ in range(n): # n번  반복\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재  단어에  대핚  정수  인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=49, padding='pre') # 데이터에  대한  패딩\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=-1)\n",
        "        for word, index in t.word_index.items():\n",
        "            if index == result: # 맊약  예측핚  단어와  인덱스와  동일한  단어가  있다면\n",
        "                break # 해당  단어가  예측  단어이므로  break\n",
        "        current_word = current_word + ' '  + word # 현재  단어  + ' ' + 예측  단어를  현재  단어로  변경\n",
        "        sentence = sentence + ' ' + word # 예측  단어를  문장에  저장\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return \"교훈 : \" + sentence"
      ],
      "metadata": {
        "id": "ritZCPXfz7tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feeling_generation(feeling_model, feeling_tokenizer, '오늘', 27))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tibb4NJGsWB5",
        "outputId": "28d68a94-5515-4148-e66e-228a529d3949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "느낌 : 오늘 하루가 지날 수록 점점 마음이 급해졌다 그래서 몇 가지 놓쳤는데 팀원이 도와주었다 어쨌든 오늘 개인 대화 기능 구현에 성공해서 마음이 놓였다 이제 팀원들을 볼 낯이 생겨서 다행이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lesson_generation(lesson_model, lesson_tokenizer, '오늘',17))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dttK54gn1DCn",
        "outputId": "74d4a119-a62e-45c2-928a-587c05e2ddab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교훈 : 오늘 공부하자 새로운 게 계속 나오고 배운 거 활용하면서 디벨롭 해나가자 좋은 분들도 계시니 나만 더 잘하면 된다\n"
          ]
        }
      ]
    }
  ]
}