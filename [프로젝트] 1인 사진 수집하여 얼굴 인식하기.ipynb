{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴인식 잠금해제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 - 얼굴 검출하여 얼굴 사진 수집하기 100장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:21: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\isfs0\\AppData\\Local\\Temp\\ipykernel_14620\\989535963.py:21: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if faces is not() :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is success\n"
     ]
    }
   ],
   "source": [
    "# 하르 캐스케이드 얼굴 검출 (Haar Cascade Face Detection) 사용 : cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if not os.path.exists('faces'):\n",
    "    os.makedirs('faces')\n",
    "    \n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "camera = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()                              # 프레임 단위로 캡처\n",
    "    \n",
    "    gray_camera = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_camera, 1.3, 6)\n",
    "\n",
    "    COLORG = (0, 200, 2) # 녹색\n",
    "    COLORB = (200, 2 ,0)\n",
    "    if faces is not() :\n",
    "        count += 1\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+ h), COLORB, 2)\n",
    "            text = \"ANALYZING...\"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "            text_x = int((x + x + w - text_size[0]) / 2)\n",
    "            text_y = int(y + h + text_size[1] + 10)  # 상자 아래에 글자 표시\n",
    "            cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            crop_face = gray_camera[y:y+h, x:x+w]\n",
    "        face = cv2.resize(crop_face, (200,200))\n",
    "        # faces/user1.jpg, faces/user2.jpg ...\n",
    "        file_name_path = os.path.join('faces', f'user{count}.jpg')\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "        cv2.imshow('face crop', face)\n",
    "    else : \n",
    "        pass\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit',frame)              # 프레임 표시\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(' ') or count == 100:  # 스페이스바가 감지되면 중지\n",
    "        break\n",
    "\n",
    "camera.release()                           # 스페이스바가 감지된 후 창을 종료\n",
    "cv2.destroyAllWindows()\n",
    "print('Analysis is success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 - 100장의 사진을 학습 시키기\n",
    " \n",
    "   모델 학습 전 i를 32비트로 변화하는 이유 : 모델 학습의 원활한 진행과 정확도 향상을 위한 중요한 단계 중 하나\n",
    "   - 데이터 형식 표준화: 머신 러닝 모델 학습에는 입력 데이터와 레이블 데이터의 데이터 형식이 일치해야 합니다. 모델 학습 시에 데이터 형식의 불일치로 인한 문제를 방지하기 위해 레이블 데이터를 표준 데이터 형식인 32비트로 변환합니다.\n",
    "   - 최적화 및 호환성: 일반적으로 많은 머신 러닝 프레임워크와 라이브러리는 32비트 정수(np.int32)를 레이블 데이터의 기본 형식으로 사용합니다. 따라서 32비트로 변환하면 호환성 문제가 줄어들고, 모델 학습 및 예측 과정이 최적화될 수 있습니다.\n",
    "   - 정수 레이블: 레이블 데이터가 정수로 표현되는 경우가 많습니다. 예를 들어, 얼굴 인식 모델의 경우 얼굴을 식별하는 데 사용되는 레이블은 일반적으로 숫자로 표현됩니다. 따라서 레이블을 정수 형식으로 변환하여 모델이 해당 레이블을 이해하고 처리할 수 있도록 합니다.\n",
    "   - 계산 및 메모리 효율성: 32비트 정수는 대부분의 시스템에서 효율적으로 처리할 수 있으며, 메모리 사용량이 적습니다. 이는 대규모 데이터셋 및 모델 학습 시에 중요한 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python-headless==4.8.1.78 --user\n",
    "%pip install opencv-contrib-python==4.8.1.78 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip3 install scikit-build\n",
    "!pip install cmake\n",
    "!pip install --user opencv-contrib-python==4.6.0.66\n",
    "!pip install opencv-python-headless==4.8.1.78\n",
    "!pip install opencv-contrib-python==4.8.1.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete\n"
     ]
    }
   ],
   "source": [
    "# model = cv2.face.LBPHFaceRecognizer_create()\n",
    "# model.train(.....)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "file_path = 'faces/'\n",
    "# 폴더 안에 파일 리스트로 변환\n",
    "onlyfiles = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles) :\n",
    "    image_path = file_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if images is None :\n",
    "        continue\n",
    "    # Training_Data 리스트에 바이트 배열로 이미지 추가\n",
    "    # 바이트 배열로 변환하면 데이터베이스에 저장하거나 네트워크를 통해 전송에 유용\n",
    "    # np.uint8 == 8비트 부호 없는 정수 형식\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "if len(Labels) == 0 :\n",
    "    print(\"NONDATA\")\n",
    "    exit()\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "model.write('./faces/my_face.xml')\n",
    "cv2.imshow(\"First face\", Training_Data[0])\n",
    "cv2.imshow(\"Last face\", Training_Data[99])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 - 얼굴 인식해서 학습한 인물인지 확인하여 'Access Granted' 나타내고  & 정확도 표 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "file_path = 'faces/'\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.read(os.path.join(file_path,'my_face.xml'))\n",
    "\n",
    "dirs = [d for d in glob.glob(file_path+\"/*\") if os.path.isdir(d)]\n",
    "print(dirs)\n",
    "\n",
    "COLORG = (0, 200, 2) # 녹색\n",
    "COLORR = (2, 0, 200)\n",
    "COLORB = (200, 2, 0)\n",
    "\n",
    "ANALYZING_TIMEOUT = 3\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while camera.isOpened() :\n",
    "    ret, frame = camera.read()\n",
    "    if not ret : \n",
    "        print(\"no frame\")\n",
    "        break\n",
    "\n",
    "    gray_camera = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_camera, 1.3, 6)\n",
    "    \n",
    "    for (x,y,w,h) in faces : \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+ h), COLORB, 2)\n",
    "        # text = \"ANALYZING...\"\n",
    "        # text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "        # text_x = int((x + x + w - text_size[0]) / 2)\n",
    "        # text_y = int(y + h + text_size[1] + 10)  # 상자 아래에 글자 표시\n",
    "        # cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        labels, confidence = model.predict(face)\n",
    "\n",
    "        if confidence < 500 :\n",
    "            accuracy = int(100*(1-confidence/300))\n",
    "       \n",
    "            if accuracy > 80 :\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+ h), COLORG, 2)\n",
    "                text = \"ACCESS SUCCESS\"\n",
    "                color = COLORG\n",
    "            \n",
    "            else :\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+ h), COLORR, 2)\n",
    "                text = \"ACCESS DENIED\"\n",
    "                color = COLORR\n",
    "                \n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "            text_x = int((x + x + w - text_size[0]) / 2)\n",
    "            text_y = int(y + h + text_size[1] + 10)  # 상자 아래에 글자 표시\n",
    "            cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            cv2.putText(frame, f'{accuracy}%', (text_x, text_y + text_size[1] + 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.imshow('Press Spacebar to Exit',frame)              # 프레임 표시\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(' ') :  # 스페이스바가 감지되면 중지\n",
    "        break\n",
    "camera.release()                           # 스페이스바가 감지된 후 창을 종료\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def collect_face_images():\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    face_samples = []  # 얼굴 이미지를 저장할 리스트\n",
    "    count = 0  # 얼굴 이미지 수\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()  # 웹캠에서 프레임 읽기\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 흑백으로 변환\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)  # 얼굴 검출\n",
    "        # multiscale 은 여러명의 얼굴이 뜰 수 있으니 내 얼굴을 기준으로 x,y 좌표를 잡으라는 정보값 지정 \n",
    "    \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray[y:y + h, x:x + w]\n",
    "            face_samples.append(face)\n",
    "            count += 1\n",
    "    \n",
    "            if count >= 100:\n",
    "                break\n",
    "    \n",
    "        cv2.imshow('Collecting Faces', frame)\n",
    "    \n",
    "        if count >= 100:\n",
    "            break\n",
    "    \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return face_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 얼굴 이미지를 학습시키기\n",
    "def train_face_recognition(face_samples):\n",
    "    model = cv2.face_LBPHFaceRecognizer.create()\n",
    "    labels = np.array([1] * len(face_samples))  # 레이블은 모두 1로 설정 (Access Granted)\n",
    "    \n",
    "    model.train(face_samples, labels)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠 다시 시작하여 얼굴 인식 수행 (Step 3)\n",
    "def face_recognition_with_model(model):\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray[y:y + h, x:x + w]\n",
    "            label, confidence = model.predict(face)\n",
    "    \n",
    "            if label == 1:  # 예측 레이블 확인하여 인물 확인\n",
    "                cv2.putText(frame, \"Access Granted\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Confidence: {confidence}\", (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Access Denied\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, f\"Confidence: {confidence}\", (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    \n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "    \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# # Step 1: 얼굴 이미지 수집\n",
    "# face_samples = collect_face_images()\n",
    "\n",
    "# # Step 2: 학습\n",
    "# model = train_face_recognition(face_samples)\n",
    "\n",
    "# # Step 3: 얼굴 인식\n",
    "# face_recognition_with_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 팀원 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Face image collection completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def collect_face_images(output_folder, max_samples=100):\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    face_samples = []  # 얼굴 이미지를 저장할 리스트\n",
    "    sample_count = 0   # 수집한 샘플 수\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray_frame[y:y+h, x:x+w]\n",
    "            face_samples.append(face)\n",
    "            sample_count += 1\n",
    "            \n",
    "            # 샘플 이미지를 파일로 저장 (예: sample_001.jpg, sample_002.jpg, ...)\n",
    "            file_name = f\"{output_folder}/sample_{sample_count:03d}.jpg\"\n",
    "            cv2.imwrite(file_name, face)\n",
    "        \n",
    "        cv2.imshow('Collecting Faces', frame)\n",
    "        \n",
    "        if sample_count >= max_samples:\n",
    "            break\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return face_samples\n",
    "\n",
    "# 샘플 얼굴 이미지를 저장할 폴더 지정\n",
    "output_folder = \"collected_samples\"\n",
    "\n",
    "# Step 1 실행: 얼굴 이미지 수집\n",
    "collected_face_samples = collect_face_images(output_folder, max_samples=100)\n",
    "\n",
    "print(\"Step 1: Face image collection completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_face_recognition(face_samples):\n",
    "    model = cv2.face_LBPHFaceRecognizer.create()\n",
    "    labels = np.array([1] * len(face_samples))  # 레이블은 모두 1로 설정 (Access Granted)\n",
    "    \n",
    "    model.train(face_samples, labels)\n",
    "    return model\n",
    "\n",
    "# Step 2 실행: 얼굴 인식 모델 학습\n",
    "trained_model = train_face_recognition(collected_face_samples)\n",
    "\n",
    "# print(\"Step 2: Face recognition model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition_with_model(model):\n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = camera.read()\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray_frame[y:y + h, x:x + w]\n",
    "            label, confidence = model.predict(face)\n",
    "    \n",
    "            if label == 1:  # 예측 레이블 확인하여 인물 확인 (Access Granted)\n",
    "                cv2.putText(frame, \"Access Granted\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Confidence: {confidence:.2f}\", (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Access Denied\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, f\"Confidence: {confidence:.2f}\", (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    \n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# # Step 3 실행: 얼굴 인식\n",
    "# face_recognition_with_model(trained_model)\n",
    "\n",
    "# print(\"Step 3: Face recognition completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
